{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 7331 - Case Study 6 - Predicting the Existence of New Particles\n",
    "Daniel Crouthamel\n",
    "\n",
    "Sophia Wu\n",
    "\n",
    "Fabio Savorgnan\n",
    "\n",
    "Bo Yun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The intention of this study is to predict the existence of new particles using a dense neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "*You should always state the objective at the beginning of every case (a guideline you should follow in real life as well) and provide some initial \"Business Understanding\" statements (i.e., what is trying to be solved for and why might it be important)*\n",
    "\n",
    "We received an abrupt request from our client in the superconductors industry to help predict the existence of new particles using a dense neural network. The goal should be to maximized accuracy. The client requires a write up on the design of the network, along with information to indicate that the model was trained appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation / Engineering\n",
    "\n",
    "*Summarize the data being used in the case using appropriate mediums (charts, graphs, tables); address questions such as: Are there missing values? Which variables are needed (which ones are not)? What assumptions or conclusions are you drawing that need to be relayed to your audience?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('data/all_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 38/38 [01:59<00:00,  3.13s/it, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:22<00:00, 22.39s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 504.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset and profile it, only need to do once - so comment out.\n",
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(df, title=\"New Particles EDA\", minimal=True)\n",
    "# profile.to_file(output_file=\"NewParticlesEDA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   # label  float64\n",
      " 1   f0       float64\n",
      " 2   f1       float64\n",
      " 3   f2       float64\n",
      " 4   f3       float64\n",
      " 5   f4       float64\n",
      " 6   f5       float64\n",
      " 7   f6       float64\n",
      " 8   f7       float64\n",
      " 9   f8       float64\n",
      " 10  f9       float64\n",
      " 11  f10      float64\n",
      " 12  f11      float64\n",
      " 13  f12      float64\n",
      " 14  f13      float64\n",
      " 15  f14      float64\n",
      " 16  f15      float64\n",
      " 17  f16      float64\n",
      " 18  f17      float64\n",
      " 19  f18      float64\n",
      " 20  f19      float64\n",
      " 21  f20      float64\n",
      " 22  f21      float64\n",
      " 23  f22      float64\n",
      " 24  f23      float64\n",
      " 25  f24      float64\n",
      " 26  f25      float64\n",
      " 27  f26      float64\n",
      " 28  mass     float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.001256e-01</td>\n",
       "      <td>1.612528e-02</td>\n",
       "      <td>4.770022e-04</td>\n",
       "      <td>2.686578e-05</td>\n",
       "      <td>1.056081e-02</td>\n",
       "      <td>-1.050026e-04</td>\n",
       "      <td>2.765919e-03</td>\n",
       "      <td>1.815953e-02</td>\n",
       "      <td>2.510948e-05</td>\n",
       "      <td>4.345870e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164789e-02</td>\n",
       "      <td>-1.127097e-04</td>\n",
       "      <td>7.686731e-05</td>\n",
       "      <td>2.909202e-04</td>\n",
       "      <td>1.228774e-02</td>\n",
       "      <td>9.778378e-03</td>\n",
       "      <td>5.269844e-03</td>\n",
       "      <td>-1.760961e-03</td>\n",
       "      <td>1.533136e-02</td>\n",
       "      <td>1.000107e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.004417e+00</td>\n",
       "      <td>9.974864e-01</td>\n",
       "      <td>1.000080e+00</td>\n",
       "      <td>9.956003e-01</td>\n",
       "      <td>9.998670e-01</td>\n",
       "      <td>1.000957e+00</td>\n",
       "      <td>9.867746e-01</td>\n",
       "      <td>9.965867e-01</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002725e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000170e+00</td>\n",
       "      <td>1.010477e+00</td>\n",
       "      <td>1.005418e+00</td>\n",
       "      <td>1.009990e+00</td>\n",
       "      <td>9.844511e-01</td>\n",
       "      <td>9.822799e-01</td>\n",
       "      <td>3.534255e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.960549e+00</td>\n",
       "      <td>-2.365355e+00</td>\n",
       "      <td>-1.732165e+00</td>\n",
       "      <td>-9.980274e+00</td>\n",
       "      <td>-1.732137e+00</td>\n",
       "      <td>-1.054221e+00</td>\n",
       "      <td>-3.034787e+00</td>\n",
       "      <td>-2.757853e+00</td>\n",
       "      <td>-1.732359e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728284e+00</td>\n",
       "      <td>-2.281867e+00</td>\n",
       "      <td>-1.731758e+00</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-3.631608e+00</td>\n",
       "      <td>-4.729473e+00</td>\n",
       "      <td>-2.062223e+01</td>\n",
       "      <td>-3.452634e+00</td>\n",
       "      <td>-2.632761e+00</td>\n",
       "      <td>5.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.288206e-01</td>\n",
       "      <td>-7.332548e-01</td>\n",
       "      <td>-8.656704e-01</td>\n",
       "      <td>-6.092291e-01</td>\n",
       "      <td>-8.658025e-01</td>\n",
       "      <td>-1.054221e+00</td>\n",
       "      <td>-7.566092e-01</td>\n",
       "      <td>-7.014146e-01</td>\n",
       "      <td>-8.656543e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.423630e-01</td>\n",
       "      <td>-7.206846e-01</td>\n",
       "      <td>-8.656855e-01</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-5.417942e-01</td>\n",
       "      <td>-5.115522e-01</td>\n",
       "      <td>-3.543870e-01</td>\n",
       "      <td>-6.925097e-01</td>\n",
       "      <td>-7.943804e-01</td>\n",
       "      <td>7.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.930319e-02</td>\n",
       "      <td>8.523957e-04</td>\n",
       "      <td>3.199154e-04</td>\n",
       "      <td>1.963316e-02</td>\n",
       "      <td>-5.070131e-04</td>\n",
       "      <td>-5.983562e-03</td>\n",
       "      <td>-1.499527e-01</td>\n",
       "      <td>-1.067553e-04</td>\n",
       "      <td>1.384781e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.992496e-02</td>\n",
       "      <td>-6.735953e-05</td>\n",
       "      <td>-4.424527e-04</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-1.602760e-01</td>\n",
       "      <td>-3.144032e-01</td>\n",
       "      <td>-3.265228e-01</td>\n",
       "      <td>-3.570301e-01</td>\n",
       "      <td>-8.828640e-02</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.900799e-01</td>\n",
       "      <td>7.347832e-01</td>\n",
       "      <td>8.659464e-01</td>\n",
       "      <td>6.798818e-01</td>\n",
       "      <td>8.657646e-01</td>\n",
       "      <td>8.504885e-01</td>\n",
       "      <td>7.686690e-01</td>\n",
       "      <td>7.013194e-01</td>\n",
       "      <td>8.665976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423185e-01</td>\n",
       "      <td>7.204921e-01</td>\n",
       "      <td>8.659566e-01</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>4.812194e-01</td>\n",
       "      <td>1.634892e-01</td>\n",
       "      <td>-2.337671e-01</td>\n",
       "      <td>4.753128e-01</td>\n",
       "      <td>7.610846e-01</td>\n",
       "      <td>1.250000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.378282e+00</td>\n",
       "      <td>2.365287e+00</td>\n",
       "      <td>1.732370e+00</td>\n",
       "      <td>4.148023e+00</td>\n",
       "      <td>1.731978e+00</td>\n",
       "      <td>4.482618e+00</td>\n",
       "      <td>3.720345e+00</td>\n",
       "      <td>2.758590e+00</td>\n",
       "      <td>1.731450e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.866367e+00</td>\n",
       "      <td>2.282217e+00</td>\n",
       "      <td>1.732740e+00</td>\n",
       "      <td>1.743123e+00</td>\n",
       "      <td>7.293420e+00</td>\n",
       "      <td>9.333287e+00</td>\n",
       "      <td>1.499064e+01</td>\n",
       "      <td>5.277313e+00</td>\n",
       "      <td>4.444690e+00</td>\n",
       "      <td>1.500000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            # label            f0            f1            f2            f3  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   5.001256e-01  1.612528e-02  4.770022e-04  2.686578e-05  1.056081e-02   \n",
       "std    5.000000e-01  1.004417e+00  9.974864e-01  1.000080e+00  9.956003e-01   \n",
       "min    0.000000e+00 -1.960549e+00 -2.365355e+00 -1.732165e+00 -9.980274e+00   \n",
       "25%    0.000000e+00 -7.288206e-01 -7.332548e-01 -8.656704e-01 -6.092291e-01   \n",
       "50%    1.000000e+00 -3.930319e-02  8.523957e-04  3.199154e-04  1.963316e-02   \n",
       "75%    1.000000e+00  6.900799e-01  7.347832e-01  8.659464e-01  6.798818e-01   \n",
       "max    1.000000e+00  4.378282e+00  2.365287e+00  1.732370e+00  4.148023e+00   \n",
       "\n",
       "                 f4            f5            f6            f7            f8  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean  -1.050026e-04  2.765919e-03  1.815953e-02  2.510948e-05  4.345870e-04   \n",
       "std    9.998670e-01  1.000957e+00  9.867746e-01  9.965867e-01  1.000007e+00   \n",
       "min   -1.732137e+00 -1.054221e+00 -3.034787e+00 -2.757853e+00 -1.732359e+00   \n",
       "25%   -8.658025e-01 -1.054221e+00 -7.566092e-01 -7.014146e-01 -8.656543e-01   \n",
       "50%   -5.070131e-04 -5.983562e-03 -1.499527e-01 -1.067553e-04  1.384781e-03   \n",
       "75%    8.657646e-01  8.504885e-01  7.686690e-01  7.013194e-01  8.665976e-01   \n",
       "max    1.731978e+00  4.482618e+00  3.720345e+00  2.758590e+00  1.731450e+00   \n",
       "\n",
       "       ...           f18           f19           f20           f21  \\\n",
       "count  ...  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   ...  1.164789e-02 -1.127097e-04  7.686731e-05  2.909202e-04   \n",
       "std    ...  1.002725e+00  1.000038e+00  1.000033e+00  1.000170e+00   \n",
       "min    ... -1.728284e+00 -2.281867e+00 -1.731758e+00 -5.736825e-01   \n",
       "25%    ... -7.423630e-01 -7.206846e-01 -8.656855e-01 -5.736825e-01   \n",
       "50%    ... -8.992496e-02 -6.735953e-05 -4.424527e-04 -5.736825e-01   \n",
       "75%    ...  6.423185e-01  7.204921e-01  8.659566e-01 -5.736825e-01   \n",
       "max    ...  5.866367e+00  2.282217e+00  1.732740e+00  1.743123e+00   \n",
       "\n",
       "                f22           f23           f24           f25           f26  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   1.228774e-02  9.778378e-03  5.269844e-03 -1.760961e-03  1.533136e-02   \n",
       "std    1.010477e+00  1.005418e+00  1.009990e+00  9.844511e-01  9.822799e-01   \n",
       "min   -3.631608e+00 -4.729473e+00 -2.062223e+01 -3.452634e+00 -2.632761e+00   \n",
       "25%   -5.417942e-01 -5.115522e-01 -3.543870e-01 -6.925097e-01 -7.943804e-01   \n",
       "50%   -1.602760e-01 -3.144032e-01 -3.265228e-01 -3.570301e-01 -8.828640e-02   \n",
       "75%    4.812194e-01  1.634892e-01 -2.337671e-01  4.753128e-01  7.610846e-01   \n",
       "max    7.293420e+00  9.333287e+00  1.499064e+01  5.277313e+00  4.444690e+00   \n",
       "\n",
       "               mass  \n",
       "count  7.000000e+06  \n",
       "mean   1.000107e+03  \n",
       "std    3.534255e+02  \n",
       "min    5.000000e+02  \n",
       "25%    7.500000e+02  \n",
       "50%    1.000000e+03  \n",
       "75%    1.250000e+03  \n",
       "max    1.500000e+03  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    3500879\n",
       "0.0    3499121\n",
       "Name: # label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"# label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information found in the Pandas Profile report reveals the following.\n",
    "\n",
    "* 7 Million rows of data\n",
    "* 28 features and 1 target\n",
    "* No missing data\n",
    "* Our reponse, # label, is nearly balanced, close to 50%.\n",
    "* We have 4 features in which there are only two values, which we could consider treating as binary/categorical.\n",
    "  * f9\n",
    "  * f13\n",
    "  * f17\n",
    "  * f21\n",
    "* The remaing features are distrubuted normally or have a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   target  float64\n",
      " 1   f0      float64\n",
      " 2   f1      float64\n",
      " 3   f2      float64\n",
      " 4   f3      float64\n",
      " 5   f4      float64\n",
      " 6   f5      float64\n",
      " 7   f6      float64\n",
      " 8   f7      float64\n",
      " 9   f8      float64\n",
      " 10  f9      float64\n",
      " 11  f10     float64\n",
      " 12  f11     float64\n",
      " 13  f12     float64\n",
      " 14  f13     float64\n",
      " 15  f14     float64\n",
      " 16  f15     float64\n",
      " 17  f16     float64\n",
      " 18  f17     float64\n",
      " 19  f18     float64\n",
      " 20  f19     float64\n",
      " 21  f20     float64\n",
      " 22  f21     float64\n",
      " 23  f22     float64\n",
      " 24  f23     float64\n",
      " 25  f24     float64\n",
      " 26  f25     float64\n",
      " 27  f26     float64\n",
      " 28  mass    float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Relabel target\n",
    "df.rename(columns={'# label': 'target'}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Preparations\n",
    "\n",
    "*Which methods are you proposing to utilize to solve the problem?  Why is this method appropriate given the business objective? How will you determine if your approach is useful (or how will you differentiate which approach is more useful than another)?  More specifically, what evaluation metrics are most useful given that the problem is a classification one (ex., Accuracy, F1-score, Precision, Recall, AUC, etc.)?*\n",
    "\n",
    "\n",
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.sample(frac=0.1, random_state=1).copy(deep=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df_small.loc[:, df_small.columns != 'target'].values\n",
    "\n",
    "y = df_small['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=30)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8370735930735931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup code for tensorboard use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\MSDS-7333-QTW\n",
      ".\\my_logs\\run_2021_11_07-07_05_03\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "# Print current path\n",
    "print(os.getcwd())\n",
    "print(run_logdir)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building & Evaluation\n",
    "\n",
    "In this case, your primary task is to construct a neural network to detect the existence of new particles and will involve the following steps:\n",
    "\n",
    "- Construct your neural network's architecture\n",
    "- Fit your neural network to your training data\n",
    "- Analyze your model's performance - referencing your chosen evaluation metric (including supplemental visuals and analysis where appropriate)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an early stopping callback\n",
    "\n",
    "This is a callback that will stop the training when the validation loss stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "safety= EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4690/4690 [==============================] - 18s 4ms/step - loss: 0.4737 - accuracy: 0.7979 - val_loss: 0.3701 - val_accuracy: 0.8376\n",
      "Epoch 2/10\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.4037 - accuracy: 0.8246 - val_loss: 0.3692 - val_accuracy: 0.8339\n",
      "Epoch 3/10\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3859 - accuracy: 0.8363 - val_loss: 0.3454 - val_accuracy: 0.8562\n",
      "Epoch 4/10\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3719 - accuracy: 0.8458 - val_loss: 0.3429 - val_accuracy: 0.8574\n",
      "Epoch 5/10\n",
      "4690/4690 [==============================] - 17s 4ms/step - loss: 0.3637 - accuracy: 0.8516 - val_loss: 0.3445 - val_accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "4690/4690 [==============================] - 16s 3ms/step - loss: 0.3647 - accuracy: 0.8521 - val_loss: 0.3337 - val_accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "4690/4690 [==============================] - 16s 3ms/step - loss: 0.3637 - accuracy: 0.8522 - val_loss: 0.3389 - val_accuracy: 0.8580\n",
      "Epoch 8/10\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3580 - accuracy: 0.8526 - val_loss: 0.3325 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3656 - accuracy: 0.8478 - val_loss: 0.3357 - val_accuracy: 0.8583\n",
      "Epoch 10/10\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.3622 - accuracy: 0.8482 - val_loss: 0.3329 - val_accuracy: 0.8564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), \n",
    "          callbacks=[tensorboard_cb, safety], batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3712      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,353\n",
      "Trainable params: 20,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310/2310 [==============================] - 3s 1ms/step - loss: 0.3329 - accuracy: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3328903615474701, 0.8563519716262817]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorsboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\MSDS-7333-QTW\n",
      ".\\my_logs\\run_2021_11_10-16_56_54\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 4.3317 - accuracy: 0.6185 - val_loss: 2.9395 - val_accuracy: 0.7228\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 2.1555 - accuracy: 0.7691 - val_loss: 1.2522 - val_accuracy: 0.8022\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.8516 - accuracy: 0.8039 - val_loss: 0.5937 - val_accuracy: 0.8002\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4861 - accuracy: 0.8170 - val_loss: 0.4373 - val_accuracy: 0.8268\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4537 - accuracy: 0.8153 - val_loss: 0.4225 - val_accuracy: 0.8308\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4261 - accuracy: 0.8287 - val_loss: 0.4233 - val_accuracy: 0.8306\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4356 - accuracy: 0.8272 - val_loss: 0.4263 - val_accuracy: 0.8323\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4284 - accuracy: 0.8297 - val_loss: 0.4289 - val_accuracy: 0.8335\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.4290 - accuracy: 0.8343\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 4.5086 - accuracy: 0.6020 - val_loss: 3.6351 - val_accuracy: 0.6667\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 3.0324 - accuracy: 0.7095 - val_loss: 2.6024 - val_accuracy: 0.7367\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 2.4125 - accuracy: 0.7472 - val_loss: 2.1459 - val_accuracy: 0.7657\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 1.8796 - accuracy: 0.7782 - val_loss: 1.6327 - val_accuracy: 0.7899\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 1.6158 - accuracy: 0.7799 - val_loss: 1.4816 - val_accuracy: 0.7894\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 8s 3ms/step - loss: 1.3461 - accuracy: 0.8025 - val_loss: 1.1566 - val_accuracy: 0.8027\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.9804 - accuracy: 0.8123 - val_loss: 0.8038 - val_accuracy: 0.8123\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.6354 - accuracy: 0.8138 - val_loss: 0.5017 - val_accuracy: 0.8157\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.4852 - accuracy: 0.8132 - val_loss: 0.4485 - val_accuracy: 0.8272\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.4457 - accuracy: 0.8207 - val_loss: 0.4370 - val_accuracy: 0.8255\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4257 - accuracy: 0.8294 - val_loss: 0.4269 - val_accuracy: 0.8323\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.4633 - accuracy: 0.8061 - val_loss: 0.4434 - val_accuracy: 0.8158\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4276 - accuracy: 0.8262 - val_loss: 0.4176 - val_accuracy: 0.8329\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4295 - accuracy: 0.8271 - val_loss: 0.4356 - val_accuracy: 0.8257\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4249 - accuracy: 0.8283 - val_loss: 0.4244 - val_accuracy: 0.8259\n",
      "Epoch 16/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4579 - accuracy: 0.8058 - val_loss: 0.4814 - val_accuracy: 0.7893\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.4813 - accuracy: 0.7898\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 3.7213 - accuracy: 0.6654 - val_loss: 2.5615 - val_accuracy: 0.7593\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 2.1586 - accuracy: 0.7842 - val_loss: 1.8695 - val_accuracy: 0.7944\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 1.4612 - accuracy: 0.7982 - val_loss: 1.2411 - val_accuracy: 0.7980\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 1.2176 - accuracy: 0.7979 - val_loss: 1.1779 - val_accuracy: 0.7994\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 1.0759 - accuracy: 0.8050 - val_loss: 0.9415 - val_accuracy: 0.8067\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.7556 - accuracy: 0.8104 - val_loss: 0.5476 - val_accuracy: 0.8148\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4644 - accuracy: 0.8238 - val_loss: 0.4265 - val_accuracy: 0.8328\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.4459 - accuracy: 0.8168 - val_loss: 0.4249 - val_accuracy: 0.8322\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 9s 3ms/step - loss: 0.4570 - accuracy: 0.8098 - val_loss: 0.4433 - val_accuracy: 0.8159\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4303 - val_accuracy: 0.8232\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4314 - accuracy: 0.8216 - val_loss: 0.4177 - val_accuracy: 0.8316\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4236 - accuracy: 0.8273 - val_loss: 0.4323 - val_accuracy: 0.8284\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4242 - accuracy: 0.8302 - val_loss: 0.4199 - val_accuracy: 0.8318\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4342 - accuracy: 0.8235 - val_loss: 0.4244 - val_accuracy: 0.8343\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.4276 - accuracy: 0.8332\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 15s 5ms/step - loss: 1.2561 - accuracy: 0.7832 - val_loss: 0.5600 - val_accuracy: 0.8098\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.5862 - accuracy: 0.7881 - val_loss: 0.4530 - val_accuracy: 0.8045\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4586 - accuracy: 0.8065 - val_loss: 0.4009 - val_accuracy: 0.8366\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.4329 - accuracy: 0.8149 - val_loss: 0.3811 - val_accuracy: 0.8397\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 10s 3ms/step - loss: 0.4167 - accuracy: 0.8189 - val_loss: 0.3778 - val_accuracy: 0.8415\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.3971 - accuracy: 0.8279 - val_loss: 0.3768 - val_accuracy: 0.8390\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3908 - accuracy: 0.8312 - val_loss: 0.3699 - val_accuracy: 0.8485\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3930 - accuracy: 0.8343 - val_loss: 0.3608 - val_accuracy: 0.8471\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3937 - accuracy: 0.8317 - val_loss: 0.3634 - val_accuracy: 0.8529\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3932 - accuracy: 0.8365 - val_loss: 0.3719 - val_accuracy: 0.8338\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3898 - accuracy: 0.8386 - val_loss: 0.3588 - val_accuracy: 0.8532\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3817 - accuracy: 0.8452 - val_loss: 0.3572 - val_accuracy: 0.8542\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3849 - accuracy: 0.8429 - val_loss: 0.3647 - val_accuracy: 0.8460\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3765 - accuracy: 0.8463 - val_loss: 0.3621 - val_accuracy: 0.8558\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.3856 - accuracy: 0.8425 - val_loss: 0.3618 - val_accuracy: 0.8518\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.3556 - accuracy: 0.8528\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 1.3392 - accuracy: 0.7733 - val_loss: 0.7610 - val_accuracy: 0.8214\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.9797 - accuracy: 0.7826 - val_loss: 0.7379 - val_accuracy: 0.8059\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.7292 - accuracy: 0.7903 - val_loss: 0.4679 - val_accuracy: 0.8212\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.5223 - accuracy: 0.7985 - val_loss: 0.4263 - val_accuracy: 0.8306\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4576 - accuracy: 0.8057 - val_loss: 0.3963 - val_accuracy: 0.8356\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4232 - accuracy: 0.8204 - val_loss: 0.3844 - val_accuracy: 0.8355\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.4083 - accuracy: 0.8265 - val_loss: 0.3809 - val_accuracy: 0.8446\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4049 - accuracy: 0.8298 - val_loss: 0.3646 - val_accuracy: 0.8465\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3913 - accuracy: 0.8399 - val_loss: 0.3659 - val_accuracy: 0.8537\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3891 - accuracy: 0.8381 - val_loss: 0.3747 - val_accuracy: 0.8442\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3940 - accuracy: 0.8347 - val_loss: 0.3709 - val_accuracy: 0.8512\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.3769 - accuracy: 0.8509\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 1.2726 - accuracy: 0.7753 - val_loss: 0.5582 - val_accuracy: 0.8225\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.6594 - accuracy: 0.7840 - val_loss: 0.4399 - val_accuracy: 0.8089\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4635 - accuracy: 0.8074 - val_loss: 0.4083 - val_accuracy: 0.8329\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4273 - accuracy: 0.8199 - val_loss: 0.3963 - val_accuracy: 0.8435\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4036 - accuracy: 0.8255 - val_loss: 0.3870 - val_accuracy: 0.8282\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3985 - accuracy: 0.8323 - val_loss: 0.3666 - val_accuracy: 0.8482\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3899 - accuracy: 0.8368 - val_loss: 0.3660 - val_accuracy: 0.8461\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3942 - accuracy: 0.8364 - val_loss: 0.3624 - val_accuracy: 0.8486\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4018 - accuracy: 0.8328 - val_loss: 0.3565 - val_accuracy: 0.8478\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.3991 - accuracy: 0.8355 - val_loss: 0.3715 - val_accuracy: 0.8501\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.3882 - accuracy: 0.8339 - val_loss: 0.3950 - val_accuracy: 0.8131\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4059 - accuracy: 0.8275 - val_loss: 0.3744 - val_accuracy: 0.8469\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.3783 - accuracy: 0.8463\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 1.2147 - accuracy: 0.7817 - val_loss: 1.2824 - val_accuracy: 0.8154\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 1.1079 - accuracy: 0.7952 - val_loss: 0.5773 - val_accuracy: 0.8057\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 0.6742 - accuracy: 0.8003 - val_loss: 0.6672 - val_accuracy: 0.7963\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.5267 - accuracy: 0.8047 - val_loss: 0.3967 - val_accuracy: 0.8289\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4351 - accuracy: 0.8248 - val_loss: 0.5954 - val_accuracy: 0.7654\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4462 - accuracy: 0.8256 - val_loss: 0.3754 - val_accuracy: 0.8402\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.4776 - accuracy: 0.8198 - val_loss: 0.3966 - val_accuracy: 0.8420\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4804 - accuracy: 0.8198 - val_loss: 0.8383 - val_accuracy: 0.7927\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.5523 - accuracy: 0.8179 - val_loss: 0.4655 - val_accuracy: 0.8397\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.4642 - accuracy: 0.8402\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 1.0143 - accuracy: 0.7927 - val_loss: 0.6954 - val_accuracy: 0.8152\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.7586 - accuracy: 0.7978 - val_loss: 0.4611 - val_accuracy: 0.8191\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 0.9197 - accuracy: 0.7978 - val_loss: 0.7448 - val_accuracy: 0.7978\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 11s 3ms/step - loss: 1.3935 - accuracy: 0.7993 - val_loss: 0.7505 - val_accuracy: 0.8049\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 11s 4ms/step - loss: 1.1485 - accuracy: 0.7932 - val_loss: 0.6602 - val_accuracy: 0.8215\n",
      "4886/4886 [==============================] - 10s 2ms/step - loss: 0.6741 - accuracy: 0.8204\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.5795 - accuracy: 0.8091 - val_loss: 0.4026 - val_accuracy: 0.8357\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.5097 - accuracy: 0.8167 - val_loss: 0.3847 - val_accuracy: 0.8446\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.6331 - accuracy: 0.8140 - val_loss: 0.4566 - val_accuracy: 0.8287\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.5595 - accuracy: 0.8128 - val_loss: 0.6364 - val_accuracy: 0.7400\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.6663 - accuracy: 0.8085 - val_loss: 0.6318 - val_accuracy: 0.8255\n",
      "4886/4886 [==============================] - 11s 2ms/step - loss: 0.6467 - accuracy: 0.8242\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 1.0949 - accuracy: 0.6943 - val_loss: 0.5327 - val_accuracy: 0.7275\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.5923 - accuracy: 0.7565 - val_loss: 0.4560 - val_accuracy: 0.8038\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4977 - accuracy: 0.7858 - val_loss: 0.3937 - val_accuracy: 0.8234\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4600 - accuracy: 0.8016 - val_loss: 0.3919 - val_accuracy: 0.8291\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4347 - accuracy: 0.8170 - val_loss: 0.3766 - val_accuracy: 0.8239\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4151 - accuracy: 0.8258 - val_loss: 0.3622 - val_accuracy: 0.8465\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4079 - accuracy: 0.8340 - val_loss: 0.3651 - val_accuracy: 0.8456\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4018 - accuracy: 0.8366 - val_loss: 0.3526 - val_accuracy: 0.8483\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3936 - accuracy: 0.8384 - val_loss: 0.3474 - val_accuracy: 0.8511\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3927 - accuracy: 0.8418 - val_loss: 0.3476 - val_accuracy: 0.8519\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3846 - accuracy: 0.8444 - val_loss: 0.3446 - val_accuracy: 0.8507\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3886 - accuracy: 0.8434 - val_loss: 0.3444 - val_accuracy: 0.8491\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3891 - accuracy: 0.8438 - val_loss: 0.3467 - val_accuracy: 0.8501\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3824 - accuracy: 0.8466 - val_loss: 0.3452 - val_accuracy: 0.8541\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3773 - accuracy: 0.8482 - val_loss: 0.3403 - val_accuracy: 0.8536\n",
      "Epoch 16/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3821 - accuracy: 0.8469 - val_loss: 0.3426 - val_accuracy: 0.8523\n",
      "Epoch 17/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3815 - accuracy: 0.8453 - val_loss: 0.3715 - val_accuracy: 0.8540\n",
      "Epoch 18/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3772 - accuracy: 0.8480 - val_loss: 0.3388 - val_accuracy: 0.8548\n",
      "Epoch 19/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3750 - accuracy: 0.8492 - val_loss: 0.3710 - val_accuracy: 0.8566\n",
      "Epoch 20/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3886 - accuracy: 0.8432 - val_loss: 0.3592 - val_accuracy: 0.8510\n",
      "Epoch 21/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3849 - accuracy: 0.8455 - val_loss: 0.3485 - val_accuracy: 0.8538\n",
      "4886/4886 [==============================] - 10s 2ms/step - loss: 0.3456 - accuracy: 0.8543\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 1.1066 - accuracy: 0.6927 - val_loss: 0.5208 - val_accuracy: 0.7955\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.5528 - accuracy: 0.7591 - val_loss: 0.4305 - val_accuracy: 0.8008\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4675 - accuracy: 0.7997 - val_loss: 0.3865 - val_accuracy: 0.8302\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4307 - accuracy: 0.8233 - val_loss: 0.3888 - val_accuracy: 0.8427\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4096 - accuracy: 0.8350 - val_loss: 0.3674 - val_accuracy: 0.8446\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4073 - accuracy: 0.8318 - val_loss: 0.3645 - val_accuracy: 0.8444\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3990 - accuracy: 0.8342 - val_loss: 0.3618 - val_accuracy: 0.8473\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3942 - accuracy: 0.8411 - val_loss: 0.3682 - val_accuracy: 0.8504\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4020 - accuracy: 0.8379 - val_loss: 0.3535 - val_accuracy: 0.8500\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3826 - accuracy: 0.8454 - val_loss: 0.3553 - val_accuracy: 0.8539\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3845 - accuracy: 0.8464 - val_loss: 0.3511 - val_accuracy: 0.8544\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3766 - accuracy: 0.8470 - val_loss: 0.3514 - val_accuracy: 0.8549\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3787 - accuracy: 0.8472 - val_loss: 0.3468 - val_accuracy: 0.8531\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3774 - accuracy: 0.8490 - val_loss: 0.3418 - val_accuracy: 0.8547\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3708 - accuracy: 0.8502 - val_loss: 0.3442 - val_accuracy: 0.8547\n",
      "Epoch 16/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3722 - accuracy: 0.8497 - val_loss: 0.3458 - val_accuracy: 0.8537\n",
      "Epoch 17/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.3769 - accuracy: 0.8479 - val_loss: 0.3441 - val_accuracy: 0.8559\n",
      "4886/4886 [==============================] - 9s 2ms/step - loss: 0.3475 - accuracy: 0.8553\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 0.8829 - accuracy: 0.7130 - val_loss: 0.4416 - val_accuracy: 0.8001\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.5009 - accuracy: 0.7783 - val_loss: 0.4282 - val_accuracy: 0.7975\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4704 - accuracy: 0.7868 - val_loss: 0.3955 - val_accuracy: 0.8230\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.4480 - accuracy: 0.8074 - val_loss: 0.3822 - val_accuracy: 0.8369\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4261 - accuracy: 0.8213 - val_loss: 0.3720 - val_accuracy: 0.8400\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4141 - accuracy: 0.8266 - val_loss: 0.3722 - val_accuracy: 0.8464\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4092 - accuracy: 0.8316 - val_loss: 0.4121 - val_accuracy: 0.8045\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4025 - accuracy: 0.8348 - val_loss: 0.3654 - val_accuracy: 0.8470\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4096 - accuracy: 0.8283 - val_loss: 0.3665 - val_accuracy: 0.8433\n",
      "Epoch 10/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4067 - accuracy: 0.8350 - val_loss: 0.3626 - val_accuracy: 0.8474\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3910 - accuracy: 0.8395 - val_loss: 0.3661 - val_accuracy: 0.8490\n",
      "Epoch 12/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3927 - accuracy: 0.8415 - val_loss: 0.3854 - val_accuracy: 0.8492\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3838 - accuracy: 0.8456 - val_loss: 0.3591 - val_accuracy: 0.8527\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3849 - accuracy: 0.8472 - val_loss: 0.3562 - val_accuracy: 0.8544\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3794 - accuracy: 0.8477 - val_loss: 0.3505 - val_accuracy: 0.8537\n",
      "Epoch 16/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3924 - accuracy: 0.8417 - val_loss: 0.3521 - val_accuracy: 0.8531\n",
      "Epoch 17/500\n",
      "3127/3127 [==============================] - 12s 4ms/step - loss: 0.3904 - accuracy: 0.8402 - val_loss: 0.3531 - val_accuracy: 0.8519\n",
      "Epoch 18/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3853 - accuracy: 0.8449 - val_loss: 0.3485 - val_accuracy: 0.8542\n",
      "Epoch 19/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3744 - accuracy: 0.8484 - val_loss: 0.3507 - val_accuracy: 0.8541\n",
      "Epoch 20/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3764 - accuracy: 0.8498 - val_loss: 0.3553 - val_accuracy: 0.8551\n",
      "Epoch 21/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.3733 - accuracy: 0.8491 - val_loss: 0.3523 - val_accuracy: 0.8513\n",
      "4886/4886 [==============================] - 10s 2ms/step - loss: 0.3541 - accuracy: 0.8516\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 17s 5ms/step - loss: 0.5001 - accuracy: 0.8014 - val_loss: 0.4038 - val_accuracy: 0.8411\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4627 - accuracy: 0.8088 - val_loss: 0.3914 - val_accuracy: 0.8183\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 14s 5ms/step - loss: 0.4325 - accuracy: 0.8249 - val_loss: 0.4133 - val_accuracy: 0.8503\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 15s 5ms/step - loss: 0.4592 - accuracy: 0.8117 - val_loss: 0.4408 - val_accuracy: 0.8474\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 15s 5ms/step - loss: 0.4415 - accuracy: 0.8252 - val_loss: 0.4192 - val_accuracy: 0.8458\n",
      "4886/4886 [==============================] - 11s 2ms/step - loss: 0.4155 - accuracy: 0.8479\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 18s 6ms/step - loss: 0.4936 - accuracy: 0.8007 - val_loss: 0.4317 - val_accuracy: 0.8249\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 15s 5ms/step - loss: 0.4806 - accuracy: 0.7994 - val_loss: 0.3980 - val_accuracy: 0.8325\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 15s 5ms/step - loss: 0.4659 - accuracy: 0.8000 - val_loss: 0.3953 - val_accuracy: 0.8282\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 14s 5ms/step - loss: 0.4426 - accuracy: 0.8165 - val_loss: 0.4289 - val_accuracy: 0.8477\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4611 - accuracy: 0.8114 - val_loss: 0.3707 - val_accuracy: 0.8459\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4519 - accuracy: 0.8192 - val_loss: 0.4184 - val_accuracy: 0.8507\n",
      "Epoch 7/500\n",
      "3127/3127 [==============================] - 14s 4ms/step - loss: 0.4462 - accuracy: 0.8209 - val_loss: 0.4146 - val_accuracy: 0.8501\n",
      "Epoch 8/500\n",
      "3127/3127 [==============================] - 13s 4ms/step - loss: 0.4636 - accuracy: 0.8016 - val_loss: 0.3857 - val_accuracy: 0.8408\n",
      "4886/4886 [==============================] - 11s 2ms/step - loss: 0.3896 - accuracy: 0.8407\n",
      "Epoch 1/500\n",
      "3127/3127 [==============================] - 18s 5ms/step - loss: 0.5080 - accuracy: 0.7987 - val_loss: 0.4160 - val_accuracy: 0.8391\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 0.4730 - accuracy: 0.8037 - val_loss: 0.4008 - val_accuracy: 0.8098\n",
      "Epoch 3/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 0.4667 - accuracy: 0.8042 - val_loss: 0.4456 - val_accuracy: 0.8502\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - 16s 5ms/step - loss: 0.4621 - accuracy: 0.8044 - val_loss: 0.4506 - val_accuracy: 0.8434\n",
      "Epoch 5/500\n",
      "3127/3127 [==============================] - 17s 5ms/step - loss: 0.4796 - accuracy: 0.8005 - val_loss: 0.4089 - val_accuracy: 0.8493\n",
      "4886/4886 [==============================] - 11s 2ms/step - loss: 0.4124 - accuracy: 0.8475\n",
      "Epoch 1/500\n",
      "4690/4690 [==============================] - 16s 3ms/step - loss: 0.8913 - accuracy: 0.7234 - val_loss: 0.4864 - val_accuracy: 0.7954\n",
      "Epoch 2/500\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.5175 - accuracy: 0.7683 - val_loss: 0.4069 - val_accuracy: 0.8080\n",
      "Epoch 3/500\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.4635 - accuracy: 0.7852 - val_loss: 0.3905 - val_accuracy: 0.8291\n",
      "Epoch 4/500\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.4284 - accuracy: 0.8093 - val_loss: 0.3839 - val_accuracy: 0.8097\n",
      "Epoch 5/500\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.4145 - accuracy: 0.8204 - val_loss: 0.3606 - val_accuracy: 0.8417\n",
      "Epoch 6/500\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.4032 - accuracy: 0.8267 - val_loss: 0.3557 - val_accuracy: 0.8440\n",
      "Epoch 7/500\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3926 - accuracy: 0.8345 - val_loss: 0.3594 - val_accuracy: 0.8420\n",
      "Epoch 8/500\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.3977 - accuracy: 0.8314 - val_loss: 0.3526 - val_accuracy: 0.8433\n",
      "Epoch 9/500\n",
      "4690/4690 [==============================] - 16s 3ms/step - loss: 0.3888 - accuracy: 0.8382 - val_loss: 0.3532 - val_accuracy: 0.8476\n",
      "Epoch 10/500\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3844 - accuracy: 0.8425 - val_loss: 0.3528 - val_accuracy: 0.8514\n",
      "Epoch 11/500\n",
      "4690/4690 [==============================] - 14s 3ms/step - loss: 0.3784 - accuracy: 0.8448 - val_loss: 0.3517 - val_accuracy: 0.8523\n",
      "Epoch 12/500\n",
      "4690/4690 [==============================] - 19s 4ms/step - loss: 0.3826 - accuracy: 0.8428 - val_loss: 0.3489 - val_accuracy: 0.8542\n",
      "Epoch 13/500\n",
      "4690/4690 [==============================] - 20s 4ms/step - loss: 0.3786 - accuracy: 0.8467 - val_loss: 0.3438 - val_accuracy: 0.8549\n",
      "Epoch 14/500\n",
      "4690/4690 [==============================] - 17s 4ms/step - loss: 0.3757 - accuracy: 0.8456 - val_loss: 0.3404 - val_accuracy: 0.8549\n",
      "Epoch 15/500\n",
      "4690/4690 [==============================] - 17s 4ms/step - loss: 0.3716 - accuracy: 0.8487 - val_loss: 0.3541 - val_accuracy: 0.8565\n",
      "Epoch 16/500\n",
      "4690/4690 [==============================] - 17s 4ms/step - loss: 0.3682 - accuracy: 0.8490 - val_loss: 0.3473 - val_accuracy: 0.8573\n",
      "Epoch 17/500\n",
      "4690/4690 [==============================] - 15s 3ms/step - loss: 0.3683 - accuracy: 0.8488 - val_loss: 0.3531 - val_accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000022225C3E160>,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  5...\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "# Print current path\n",
    "print(os.getcwd())\n",
    "print(run_logdir)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[28]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(.2, input_shape=(2,)))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    #optimizer = 'adam'\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_reg = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 500)\n",
    "}\n",
    "\n",
    "safety = EarlyStopping(monitor='val_loss', patience=3, min_delta=2e-4)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=5, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=500,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  callbacks=[tensorboard_cb, safety], batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 17, 'n_hidden': 2}\n",
      "-0.3490656912326813\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      hp.Choice('units', [8, 16, 32]),\n",
    "      activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(.2, input_shape=(2,)))  \n",
    "  model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy())\n",
    "  return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 09s]\n",
      "val_loss: 0.39247244596481323\n",
      "\n",
      "Best val_loss So Far: 0.3811619281768799\n",
      "Total elapsed time: 00h 00m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=1000)\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000022234AB41C0>\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/particle_random_cv\\assets\n"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.save('models/particle_random_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
