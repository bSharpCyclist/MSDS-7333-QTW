{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1\n",
    "\n",
    "## Business Understanding\n",
    "You should always state the objective at the beginning of every case (a guideline you should follow in real life as well) and provide some initial \"Business Understanding\" statements (i.e., what is trying to be solved for and why might it be important)\n",
    "\n",
    "build a linear regression model using L1 or L2 regularization (or both) to predict the critical temperature. In addition, include in your write-up which variable carries the most importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluation and Engineering\n",
    "Summarize the data being used in the case using appropriate mediums (charts, graphs, tables); address questions such as: Are there missing values? Which variables are needed (which ones are not)? What assumptions or conclusions are you drawing that need to be relayed to your audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21263 entries, 0 to 21262\n",
      "Columns: 169 entries, number_of_elements to material\n",
      "dtypes: float64(156), int64(12), object(1)\n",
      "memory usage: 27.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Po</th>\n",
       "      <th>At</th>\n",
       "      <th>Rn</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.115224</td>\n",
       "      <td>87.557631</td>\n",
       "      <td>72.988310</td>\n",
       "      <td>71.290627</td>\n",
       "      <td>58.539916</td>\n",
       "      <td>1.165608</td>\n",
       "      <td>1.063884</td>\n",
       "      <td>115.601251</td>\n",
       "      <td>33.225218</td>\n",
       "      <td>44.391893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.201009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.421219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.439295</td>\n",
       "      <td>29.676497</td>\n",
       "      <td>33.490406</td>\n",
       "      <td>31.030272</td>\n",
       "      <td>36.651067</td>\n",
       "      <td>0.364930</td>\n",
       "      <td>0.401423</td>\n",
       "      <td>54.626887</td>\n",
       "      <td>26.967752</td>\n",
       "      <td>20.035430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307888</td>\n",
       "      <td>0.717975</td>\n",
       "      <td>0.205846</td>\n",
       "      <td>0.272298</td>\n",
       "      <td>0.274365</td>\n",
       "      <td>0.655927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.254362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.941000</td>\n",
       "      <td>6.423452</td>\n",
       "      <td>5.320573</td>\n",
       "      <td>1.960849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>72.458076</td>\n",
       "      <td>52.143839</td>\n",
       "      <td>58.041225</td>\n",
       "      <td>35.248990</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.775363</td>\n",
       "      <td>78.512902</td>\n",
       "      <td>16.824174</td>\n",
       "      <td>32.890369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>84.922750</td>\n",
       "      <td>60.696571</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>39.918385</td>\n",
       "      <td>1.199541</td>\n",
       "      <td>1.146783</td>\n",
       "      <td>122.906070</td>\n",
       "      <td>26.636008</td>\n",
       "      <td>45.123500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.404410</td>\n",
       "      <td>86.103540</td>\n",
       "      <td>78.116681</td>\n",
       "      <td>73.113234</td>\n",
       "      <td>1.444537</td>\n",
       "      <td>1.359418</td>\n",
       "      <td>154.119320</td>\n",
       "      <td>38.356908</td>\n",
       "      <td>59.322812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>1.983797</td>\n",
       "      <td>1.958203</td>\n",
       "      <td>207.972460</td>\n",
       "      <td>205.589910</td>\n",
       "      <td>101.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "count        21263.000000      21263.000000          21263.000000   \n",
       "mean             4.115224         87.557631             72.988310   \n",
       "std              1.439295         29.676497             33.490406   \n",
       "min              1.000000          6.941000              6.423452   \n",
       "25%              3.000000         72.458076             52.143839   \n",
       "50%              4.000000         84.922750             60.696571   \n",
       "75%              5.000000        100.404410             86.103540   \n",
       "max              9.000000        208.980400            208.980400   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "count       21263.000000           21263.000000         21263.000000   \n",
       "mean           71.290627              58.539916             1.165608   \n",
       "std            31.030272              36.651067             0.364930   \n",
       "min             5.320573               1.960849             0.000000   \n",
       "25%            58.041225              35.248990             0.966676   \n",
       "50%            66.361592              39.918385             1.199541   \n",
       "75%            78.116681              73.113234             1.444537   \n",
       "max           208.980400             208.980400             1.983797   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "count             21263.000000       21263.000000           21263.000000   \n",
       "mean                  1.063884         115.601251              33.225218   \n",
       "std                   0.401423          54.626887              26.967752   \n",
       "min                   0.000000           0.000000               0.000000   \n",
       "25%                   0.775363          78.512902              16.824174   \n",
       "50%                   1.146783         122.906070              26.636008   \n",
       "75%                   1.359418         154.119320              38.356908   \n",
       "max                   1.958203         207.972460             205.589910   \n",
       "\n",
       "       std_atomic_mass  ...            Pt            Au            Hg  \\\n",
       "count     21263.000000  ...  21263.000000  21263.000000  21263.000000   \n",
       "mean         44.391893  ...      0.034108      0.020535      0.036663   \n",
       "std          20.035430  ...      0.307888      0.717975      0.205846   \n",
       "min           0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%          32.890369  ...      0.000000      0.000000      0.000000   \n",
       "50%          45.123500  ...      0.000000      0.000000      0.000000   \n",
       "75%          59.322812  ...      0.000000      0.000000      0.000000   \n",
       "max         101.019700  ...      5.800000     64.000000      8.000000   \n",
       "\n",
       "                 Tl            Pb            Bi       Po       At       Rn  \\\n",
       "count  21263.000000  21263.000000  21263.000000  21263.0  21263.0  21263.0   \n",
       "mean       0.047954      0.042461      0.201009      0.0      0.0      0.0   \n",
       "std        0.272298      0.274365      0.655927      0.0      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "max        7.000000     19.000000     14.000000      0.0      0.0      0.0   \n",
       "\n",
       "       critical_temp  \n",
       "count   21263.000000  \n",
       "mean       34.421219  \n",
       "std        34.254362  \n",
       "min         0.000210  \n",
       "25%         5.365000  \n",
       "50%        20.000000  \n",
       "75%        63.000000  \n",
       "max       185.000000  \n",
       "\n",
       "[8 rows x 168 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data\n",
    "data_train = pd.read_csv('./data/train.csv')\n",
    "data_materials = pd.read_csv('./data/unique_m.csv')\n",
    "\n",
    "# Drop the duplicate column 'critical_temp' in the\n",
    "\n",
    "data_train = data_train.drop(['critical_temp'], axis=1)\n",
    "\n",
    "# Merge the two frames\n",
    "data = pd.merge(data_train, data_materials, left_index=True, right_index=True)\n",
    "\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Columns with missing data?\n",
    "print(data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['He', 'Ne', 'Ar', 'Kr', 'Xe', 'Pm', 'Po', 'At', 'Rn'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with a Constant value\n",
    "data.columns[data.nunique() <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21263, 159)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with constant values\n",
    "data.drop(columns=['material', 'He', 'Ne', 'Ar', 'Kr', 'Xe', 'Pm', 'Po', 'At', 'Rn'], inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our standard numpy stuff\n",
    "X = data.drop(columns=['critical_temp']).values\n",
    "y = data.loc[:,'critical_temp'].values\n",
    "\n",
    "X_df = data.drop(columns=['critical_temp']).copy(deep=True)\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = X_df.columns\n",
    "\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(len(X_df.columns))]\n",
    "\n",
    "# vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "0.7129520975572088\n",
      "{'lasso__alpha': 0.3}\n",
      "\n",
      "Ridge\n",
      "0.7065312755243307\n",
      "{'ridge__alpha': 1000}\n",
      "\n",
      "Elastic\n",
      "0.7083853891920866\n",
      "{'elasticnet__alpha': 0.3, 'elasticnet__l1_ratio': 0.9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stats.stackexchange.com/questions/445259/combining-pca-feature-scaling-and-cross-validation-without-training-test-data\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=1)\n",
    "\n",
    "lasso_pipe_svc = make_pipeline(RobustScaler(), Lasso(random_state=1))\n",
    "ridge_pipe_svc = make_pipeline(RobustScaler(), Ridge(random_state=1))\n",
    "elastic_pipe_svc = make_pipeline(RobustScaler(), ElasticNet(random_state=1))\n",
    "\n",
    "#pipe_svc = make_pipeline(RobustScaler(), Ridge(random_state=1))\n",
    "#pipe_svc = make_pipeline(StandardScaler(), Lasso(random_state=1))\n",
    "\n",
    "#param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_range = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 10, 100, 1000, 10000]\n",
    "param_l1_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "param_grid_lasso = [{'lasso__alpha': param_range}]\n",
    "param_grid_ridge = [{'ridge__alpha': param_range}]\n",
    "param_grid_elastic = [{'elasticnet__alpha': param_range, 'elasticnet__l1_ratio': param_l1_ratio}]\n",
    "\n",
    "gs_lasso = GridSearchCV(estimator=lasso_pipe_svc, param_grid=param_grid_lasso, scoring='r2', cv=5, n_jobs=-1)\n",
    "gs_lasso.fit(X_train, y_train)\n",
    "\n",
    "gs_ridge = GridSearchCV(estimator=ridge_pipe_svc, param_grid=param_grid_ridge, scoring='r2', cv=5, n_jobs=-1)\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "\n",
    "gs_elastic = GridSearchCV(estimator=elastic_pipe_svc, param_grid=param_grid_elastic, scoring='r2', cv=5, n_jobs=-1)\n",
    "gs_elastic.fit(X_train, y_train)\n",
    "\n",
    "print(\"Lasso\")\n",
    "print(gs_lasso.best_score_)\n",
    "print(gs_lasso.best_params_)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Ridge\")\n",
    "print(gs_ridge.best_score_)\n",
    "print(gs_ridge.best_params_)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Elastic\")\n",
    "print(gs_elastic.best_score_)\n",
    "print(gs_elastic.best_params_)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R2 -> 0.7197254814065868\n",
      "MAE -> 13.660714491348584\n",
      "\n",
      "Ridge\n",
      "R2 -> 0.7264906957630278\n",
      "MAE -> 13.359929361601813\n",
      "\n",
      "Elastic\n",
      "R2 -> 0.7146988481193569\n",
      "MAE -> 13.811785860925973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Note the X_test gets run through the pipeline above! Very important, it means that the scaler is also run on the test data\n",
    "y_lasso_pred = gs_lasso.predict(X_test)\n",
    "y_ridge_pred = gs_ridge.predict(X_test)\n",
    "y_elastic_pred = gs_elastic.predict(X_test)\n",
    "\n",
    "print(\"Lasso\")\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_lasso_pred))\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_lasso_pred))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Ridge\")\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_ridge_pred))\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_ridge_pred))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Elastic\")\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_elastic_pred))\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_elastic_pred))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a1962ff4b7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcols_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lasso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "#print()\n",
    "#print(gs.best_estimator_['lasso'].coef_)\n",
    "idx = 0\n",
    "cnt = 0\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "for x in gs.best_estimator_['lasso'].coef_:\n",
    "    print(data.columns[idx], x)\n",
    "    idx += 1\n",
    "    if x == 0:\n",
    "        cnt += 1\n",
    "        cols_to_drop.append(data.columns[idx])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data.drop(columns=cols_to_drop).copy(deep=True)\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = X_df.columns\n",
    "\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(len(X_df.columns))]\n",
    "\n",
    "# vif_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3953889078838669\n",
      "{'ridge__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "X = X_df.drop(columns=['critical_temp']).values\n",
    "y = data.loc[:,'critical_temp'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=1)\n",
    "\n",
    "pipe_svc = make_pipeline(RobustScaler(), Ridge(random_state=1))\n",
    "#pipe_svc = make_pipeline(StandardScaler(), LogisticRegression(random_state=1))\n",
    "\n",
    "\n",
    "#param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_range = [0.001, 0.01, 0.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "\n",
    "param_grid = [{'ridge__alpha': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555869901734685"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.predict(X_test)\n",
    "\n",
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lasso'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d8df42d50d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lasso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# Not an int, try get step by name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lasso'"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "for x in gs.best_estimator_['lasso'].coef_:\n",
    "    print(data.columns[idx], x)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 168/168 [00:01<00:00, 120.42it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s]\n"
     ]
    }
   ],
   "source": [
    "## install pandas 1.2.4\n",
    "## pip install pandas-profiling==2.8.0\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\", minimal=True)\n",
    "\n",
    "profile.to_file(output_file=\"PandasProfile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparations\n",
    "Which methods are you proposing to utilize to solve the problem?  Why is this method appropriate given the business objective? How will you determine if your approach is useful (or how will you differentiate which approach is more useful than another)?  More specifically, what evaluation metrics are most useful given that the problem is a regression one (ex., RMSE, logloss, MAE, etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation\n",
    "In this case, your primary task is to build a linear regression model using L1 or L2 regularization (or both) to predict the critical temperature and will involve the following steps:\n",
    "\n",
    "- Specify your sampling methodology\n",
    "- Setup your model(s) - specifying the regularization type chosen and including the parameters utilized by the model\n",
    "- Analyze your model's performance - referencing your chosen evaluation metric (including supplemental visuals and analysis where appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability & Explainability\n",
    "Using at least one of your models above (if multiple were trained):\n",
    "\n",
    "- Which variable(s) was (were) \"\"most important\"\" and why?  How did you come to the conclusion and how should your audience interpret this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Conclusions\n",
    "After all of your technical analysis and modeling; what are you proposing to your audience and why?  How should they view your results and what should they consider when moving forward?  Are there other approaches you'd recommend exploring?  This is where you \"bring it all home\" in language they understand."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
