{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 7331 - Case Study 6 - Predicting the Existence of New Particles\n",
    "Daniel Crouthamel\n",
    "\n",
    "Sophia Wu\n",
    "\n",
    "Fabio Savorgnan\n",
    "\n",
    "Bo Yun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The intention of this study is to predict the existence of new particles using a dense neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "*You should always state the objective at the beginning of every case (a guideline you should follow in real life as well) and provide some initial \"Business Understanding\" statements (i.e., what is trying to be solved for and why might it be important)*\n",
    "\n",
    "We received an abrupt request from our client in the superconductors industry to help predict the existence of new particles using a dense neural network. The goal is to maximize accuracy. The client requires a write up on the design of the network, along with information to indicate that the model was trained appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation / Engineering\n",
    "\n",
    "*Summarize the data being used in the case using appropriate mediums (charts, graphs, tables); address questions such as: Are there missing values? Which variables are needed (which ones are not)? What assumptions or conclusions are you drawing that need to be relayed to your audience?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('/Users/boyun/Desktop/SMU/DS7333-QuantifyingTheWorld/all_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 38/38 [01:59<00:00,  3.13s/it, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:22<00:00, 22.39s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 504.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset and profile it, only need to do once - so comment out.\n",
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(df, title=\"New Particles EDA\", minimal=True)\n",
    "# profile.to_file(output_file=\"NewParticlesEDA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   # label  float64\n",
      " 1   f0       float64\n",
      " 2   f1       float64\n",
      " 3   f2       float64\n",
      " 4   f3       float64\n",
      " 5   f4       float64\n",
      " 6   f5       float64\n",
      " 7   f6       float64\n",
      " 8   f7       float64\n",
      " 9   f8       float64\n",
      " 10  f9       float64\n",
      " 11  f10      float64\n",
      " 12  f11      float64\n",
      " 13  f12      float64\n",
      " 14  f13      float64\n",
      " 15  f14      float64\n",
      " 16  f15      float64\n",
      " 17  f16      float64\n",
      " 18  f17      float64\n",
      " 19  f18      float64\n",
      " 20  f19      float64\n",
      " 21  f20      float64\n",
      " 22  f21      float64\n",
      " 23  f22      float64\n",
      " 24  f23      float64\n",
      " 25  f24      float64\n",
      " 26  f25      float64\n",
      " 27  f26      float64\n",
      " 28  mass     float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>7.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.001256e-01</td>\n",
       "      <td>1.612528e-02</td>\n",
       "      <td>4.770022e-04</td>\n",
       "      <td>2.686578e-05</td>\n",
       "      <td>1.056081e-02</td>\n",
       "      <td>-1.050026e-04</td>\n",
       "      <td>2.765919e-03</td>\n",
       "      <td>1.815953e-02</td>\n",
       "      <td>2.510948e-05</td>\n",
       "      <td>4.345870e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164789e-02</td>\n",
       "      <td>-1.127097e-04</td>\n",
       "      <td>7.686731e-05</td>\n",
       "      <td>2.909202e-04</td>\n",
       "      <td>1.228774e-02</td>\n",
       "      <td>9.778378e-03</td>\n",
       "      <td>5.269844e-03</td>\n",
       "      <td>-1.760961e-03</td>\n",
       "      <td>1.533136e-02</td>\n",
       "      <td>1.000107e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.004417e+00</td>\n",
       "      <td>9.974864e-01</td>\n",
       "      <td>1.000080e+00</td>\n",
       "      <td>9.956003e-01</td>\n",
       "      <td>9.998670e-01</td>\n",
       "      <td>1.000957e+00</td>\n",
       "      <td>9.867746e-01</td>\n",
       "      <td>9.965867e-01</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002725e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000170e+00</td>\n",
       "      <td>1.010477e+00</td>\n",
       "      <td>1.005418e+00</td>\n",
       "      <td>1.009990e+00</td>\n",
       "      <td>9.844511e-01</td>\n",
       "      <td>9.822799e-01</td>\n",
       "      <td>3.534255e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.960549e+00</td>\n",
       "      <td>-2.365355e+00</td>\n",
       "      <td>-1.732165e+00</td>\n",
       "      <td>-9.980274e+00</td>\n",
       "      <td>-1.732137e+00</td>\n",
       "      <td>-1.054221e+00</td>\n",
       "      <td>-3.034787e+00</td>\n",
       "      <td>-2.757853e+00</td>\n",
       "      <td>-1.732359e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728284e+00</td>\n",
       "      <td>-2.281867e+00</td>\n",
       "      <td>-1.731758e+00</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-3.631608e+00</td>\n",
       "      <td>-4.729473e+00</td>\n",
       "      <td>-2.062223e+01</td>\n",
       "      <td>-3.452634e+00</td>\n",
       "      <td>-2.632761e+00</td>\n",
       "      <td>5.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.288206e-01</td>\n",
       "      <td>-7.332548e-01</td>\n",
       "      <td>-8.656704e-01</td>\n",
       "      <td>-6.092291e-01</td>\n",
       "      <td>-8.658025e-01</td>\n",
       "      <td>-1.054221e+00</td>\n",
       "      <td>-7.566092e-01</td>\n",
       "      <td>-7.014146e-01</td>\n",
       "      <td>-8.656543e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.423630e-01</td>\n",
       "      <td>-7.206846e-01</td>\n",
       "      <td>-8.656855e-01</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-5.417942e-01</td>\n",
       "      <td>-5.115522e-01</td>\n",
       "      <td>-3.543870e-01</td>\n",
       "      <td>-6.925097e-01</td>\n",
       "      <td>-7.943804e-01</td>\n",
       "      <td>7.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.930319e-02</td>\n",
       "      <td>8.523957e-04</td>\n",
       "      <td>3.199154e-04</td>\n",
       "      <td>1.963316e-02</td>\n",
       "      <td>-5.070131e-04</td>\n",
       "      <td>-5.983562e-03</td>\n",
       "      <td>-1.499527e-01</td>\n",
       "      <td>-1.067553e-04</td>\n",
       "      <td>1.384781e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.992496e-02</td>\n",
       "      <td>-6.735953e-05</td>\n",
       "      <td>-4.424527e-04</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>-1.602760e-01</td>\n",
       "      <td>-3.144032e-01</td>\n",
       "      <td>-3.265228e-01</td>\n",
       "      <td>-3.570301e-01</td>\n",
       "      <td>-8.828640e-02</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.900799e-01</td>\n",
       "      <td>7.347832e-01</td>\n",
       "      <td>8.659464e-01</td>\n",
       "      <td>6.798818e-01</td>\n",
       "      <td>8.657646e-01</td>\n",
       "      <td>8.504885e-01</td>\n",
       "      <td>7.686690e-01</td>\n",
       "      <td>7.013194e-01</td>\n",
       "      <td>8.665976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423185e-01</td>\n",
       "      <td>7.204921e-01</td>\n",
       "      <td>8.659566e-01</td>\n",
       "      <td>-5.736825e-01</td>\n",
       "      <td>4.812194e-01</td>\n",
       "      <td>1.634892e-01</td>\n",
       "      <td>-2.337671e-01</td>\n",
       "      <td>4.753128e-01</td>\n",
       "      <td>7.610846e-01</td>\n",
       "      <td>1.250000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.378282e+00</td>\n",
       "      <td>2.365287e+00</td>\n",
       "      <td>1.732370e+00</td>\n",
       "      <td>4.148023e+00</td>\n",
       "      <td>1.731978e+00</td>\n",
       "      <td>4.482618e+00</td>\n",
       "      <td>3.720345e+00</td>\n",
       "      <td>2.758590e+00</td>\n",
       "      <td>1.731450e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.866367e+00</td>\n",
       "      <td>2.282217e+00</td>\n",
       "      <td>1.732740e+00</td>\n",
       "      <td>1.743123e+00</td>\n",
       "      <td>7.293420e+00</td>\n",
       "      <td>9.333287e+00</td>\n",
       "      <td>1.499064e+01</td>\n",
       "      <td>5.277313e+00</td>\n",
       "      <td>4.444690e+00</td>\n",
       "      <td>1.500000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            # label            f0            f1            f2            f3  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   5.001256e-01  1.612528e-02  4.770022e-04  2.686578e-05  1.056081e-02   \n",
       "std    5.000000e-01  1.004417e+00  9.974864e-01  1.000080e+00  9.956003e-01   \n",
       "min    0.000000e+00 -1.960549e+00 -2.365355e+00 -1.732165e+00 -9.980274e+00   \n",
       "25%    0.000000e+00 -7.288206e-01 -7.332548e-01 -8.656704e-01 -6.092291e-01   \n",
       "50%    1.000000e+00 -3.930319e-02  8.523957e-04  3.199154e-04  1.963316e-02   \n",
       "75%    1.000000e+00  6.900799e-01  7.347832e-01  8.659464e-01  6.798818e-01   \n",
       "max    1.000000e+00  4.378282e+00  2.365287e+00  1.732370e+00  4.148023e+00   \n",
       "\n",
       "                 f4            f5            f6            f7            f8  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean  -1.050026e-04  2.765919e-03  1.815953e-02  2.510948e-05  4.345870e-04   \n",
       "std    9.998670e-01  1.000957e+00  9.867746e-01  9.965867e-01  1.000007e+00   \n",
       "min   -1.732137e+00 -1.054221e+00 -3.034787e+00 -2.757853e+00 -1.732359e+00   \n",
       "25%   -8.658025e-01 -1.054221e+00 -7.566092e-01 -7.014146e-01 -8.656543e-01   \n",
       "50%   -5.070131e-04 -5.983562e-03 -1.499527e-01 -1.067553e-04  1.384781e-03   \n",
       "75%    8.657646e-01  8.504885e-01  7.686690e-01  7.013194e-01  8.665976e-01   \n",
       "max    1.731978e+00  4.482618e+00  3.720345e+00  2.758590e+00  1.731450e+00   \n",
       "\n",
       "       ...           f18           f19           f20           f21  \\\n",
       "count  ...  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   ...  1.164789e-02 -1.127097e-04  7.686731e-05  2.909202e-04   \n",
       "std    ...  1.002725e+00  1.000038e+00  1.000033e+00  1.000170e+00   \n",
       "min    ... -1.728284e+00 -2.281867e+00 -1.731758e+00 -5.736825e-01   \n",
       "25%    ... -7.423630e-01 -7.206846e-01 -8.656855e-01 -5.736825e-01   \n",
       "50%    ... -8.992496e-02 -6.735953e-05 -4.424527e-04 -5.736825e-01   \n",
       "75%    ...  6.423185e-01  7.204921e-01  8.659566e-01 -5.736825e-01   \n",
       "max    ...  5.866367e+00  2.282217e+00  1.732740e+00  1.743123e+00   \n",
       "\n",
       "                f22           f23           f24           f25           f26  \\\n",
       "count  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06  7.000000e+06   \n",
       "mean   1.228774e-02  9.778378e-03  5.269844e-03 -1.760961e-03  1.533136e-02   \n",
       "std    1.010477e+00  1.005418e+00  1.009990e+00  9.844511e-01  9.822799e-01   \n",
       "min   -3.631608e+00 -4.729473e+00 -2.062223e+01 -3.452634e+00 -2.632761e+00   \n",
       "25%   -5.417942e-01 -5.115522e-01 -3.543870e-01 -6.925097e-01 -7.943804e-01   \n",
       "50%   -1.602760e-01 -3.144032e-01 -3.265228e-01 -3.570301e-01 -8.828640e-02   \n",
       "75%    4.812194e-01  1.634892e-01 -2.337671e-01  4.753128e-01  7.610846e-01   \n",
       "max    7.293420e+00  9.333287e+00  1.499064e+01  5.277313e+00  4.444690e+00   \n",
       "\n",
       "               mass  \n",
       "count  7.000000e+06  \n",
       "mean   1.000107e+03  \n",
       "std    3.534255e+02  \n",
       "min    5.000000e+02  \n",
       "25%    7.500000e+02  \n",
       "50%    1.000000e+03  \n",
       "75%    1.250000e+03  \n",
       "max    1.500000e+03  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    3500879\n",
       "0.0    3499121\n",
       "Name: # label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"# label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information found in the Pandas Profile report reveals the following.\n",
    "\n",
    "* 7 Million rows of data\n",
    "* 28 features and 1 target\n",
    "* No missing data\n",
    "* Our reponse, # label, is nearly balanced, close to 50%.\n",
    "* We have 4 features in which there are only two values, which we could consider treating as binary/categorical.\n",
    "  * f9\n",
    "  * f13\n",
    "  * f17\n",
    "  * f21\n",
    "* The remaing features are distrubuted normally or have a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   target  float64\n",
      " 1   f0      float64\n",
      " 2   f1      float64\n",
      " 3   f2      float64\n",
      " 4   f3      float64\n",
      " 5   f4      float64\n",
      " 6   f5      float64\n",
      " 7   f6      float64\n",
      " 8   f7      float64\n",
      " 9   f8      float64\n",
      " 10  f9      float64\n",
      " 11  f10     float64\n",
      " 12  f11     float64\n",
      " 13  f12     float64\n",
      " 14  f13     float64\n",
      " 15  f14     float64\n",
      " 16  f15     float64\n",
      " 17  f16     float64\n",
      " 18  f17     float64\n",
      " 19  f18     float64\n",
      " 20  f19     float64\n",
      " 21  f20     float64\n",
      " 22  f21     float64\n",
      " 23  f22     float64\n",
      " 24  f23     float64\n",
      " 25  f24     float64\n",
      " 26  f25     float64\n",
      " 27  f26     float64\n",
      " 28  mass    float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Relabel target\n",
    "df.rename(columns={'# label': 'target'}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Preparations\n",
    "\n",
    "*Which methods are you proposing to utilize to solve the problem?  Why is this method appropriate given the business objective? How will you determine if your approach is useful (or how will you differentiate which approach is more useful than another)?  More specifically, what evaluation metrics are most useful given that the problem is a classification one (ex., Accuracy, F1-score, Precision, Recall, AUC, etc.)?*\n",
    "\n",
    "\n",
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.loc[:, df_small.columns != 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.sample(frac=0.1, random_state=1).copy(deep=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df_small.loc[:, df_small.columns != 'target'].values\n",
    "\n",
    "y = df_small['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=30)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8370735930735931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch LR\n",
    "- The best accuracy score observed is 83.6%. \n",
    "- Best Hyperparameters: {'C': 0.001, 'penalty': 'none', 'solver': 'newton-cg'}\n",
    "- We will compare this result to the Neural Network result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyun/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/boyun/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.83668143 0.83581           nan        nan        nan 0.83564\n",
      " 0.83659286 0.83580429 0.83515143        nan        nan        nan\n",
      " 0.83668143 0.83581           nan        nan        nan 0.83661286\n",
      " 0.83667571 0.83579    0.83653           nan        nan        nan\n",
      " 0.83668143 0.83581           nan        nan        nan 0.83665714\n",
      " 0.83667429 0.83618    0.83664429        nan        nan        nan\n",
      " 0.83668143 0.83581           nan        nan        nan 0.83666286\n",
      " 0.83668143 0.83594    0.83667429        nan        nan        nan\n",
      " 0.83668143 0.83581           nan        nan        nan 0.83666143\n",
      " 0.83668143 0.83579286 0.83668           nan        nan        nan\n",
      " 0.83668143 0.83581           nan        nan        nan 0.83667286\n",
      " 0.83668143 0.83589714 0.83667714        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/boyun/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8366814285714286\n",
      "Best Hyperparameters: {'C': 0.001, 'penalty': 'none', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "\n",
    "# Execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# Summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch LR feature importance \n",
    "- Feature #6 and Feature #27 are the most important variables in the LR model. \n",
    "- Even though we do not have a domain expertise on these important features, we will communicate these findings to our client for their reference. \n",
    "- Depending on how much the interpretability of the model affects our client's understanding of the business performance, this information can be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.51011\n",
      "Feature: 1, Score: -0.00452\n",
      "Feature: 2, Score: -0.00040\n",
      "Feature: 3, Score: 0.46035\n",
      "Feature: 4, Score: 0.00083\n",
      "Feature: 5, Score: -0.02481\n",
      "Feature: 6, Score: 1.48715\n",
      "Feature: 7, Score: 0.00461\n",
      "Feature: 8, Score: 0.00445\n",
      "Feature: 9, Score: 0.09910\n",
      "Feature: 10, Score: 0.45446\n",
      "Feature: 11, Score: 0.01179\n",
      "Feature: 12, Score: 0.00235\n",
      "Feature: 13, Score: 0.10771\n",
      "Feature: 14, Score: 0.19335\n",
      "Feature: 15, Score: 0.00393\n",
      "Feature: 16, Score: 0.00455\n",
      "Feature: 17, Score: 0.06070\n",
      "Feature: 18, Score: 0.10612\n",
      "Feature: 19, Score: -0.00532\n",
      "Feature: 20, Score: 0.00241\n",
      "Feature: 21, Score: 0.03466\n",
      "Feature: 22, Score: -0.03248\n",
      "Feature: 23, Score: -0.11218\n",
      "Feature: 24, Score: -0.00915\n",
      "Feature: 25, Score: 0.07303\n",
      "Feature: 26, Score: 0.35706\n",
      "Feature: 27, Score: -0.97617\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get importance\n",
    "importance = lr.coef_[0]\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup code for tensorboard use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/boyun/Desktop/SMU/DS7333-QuantifyingTheWorld/MSDS-7333-QTW\n",
      "./my_logs/run_2021_11_14-09_42_56\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "# Print current path\n",
    "print(os.getcwd())\n",
    "print(run_logdir)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building & Evaluation\n",
    "\n",
    "In this case, your primary task is to construct a neural network to detect the existence of new particles and will involve the following steps:\n",
    "\n",
    "- Construct your neural network's architecture\n",
    "- Fit your neural network to your training data\n",
    "- Analyze your model's performance - referencing your chosen evaluation metric (including supplemental visuals and analysis where appropriate)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an early stopping callback\n",
    "\n",
    "This is a callback that will stop the training when the validation loss stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "safety= EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 7s 10ms/step - loss: 0.6588 - accuracy: 0.7703 - val_loss: 0.4092 - val_accuracy: 0.8097\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5213 - accuracy: 0.7854 - val_loss: 0.4062 - val_accuracy: 0.8225\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4768 - accuracy: 0.7863 - val_loss: 0.4402 - val_accuracy: 0.7682\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4586 - accuracy: 0.8000 - val_loss: 0.4016 - val_accuracy: 0.8020\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.4397 - accuracy: 0.8061 - val_loss: 0.3846 - val_accuracy: 0.8228\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4312 - accuracy: 0.8083 - val_loss: 0.3844 - val_accuracy: 0.8236\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4271 - accuracy: 0.8126 - val_loss: 0.3810 - val_accuracy: 0.8261\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4582 - accuracy: 0.7981 - val_loss: 0.3849 - val_accuracy: 0.8153\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4224 - accuracy: 0.8151 - val_loss: 0.3804 - val_accuracy: 0.8202\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.4261 - accuracy: 0.8069 - val_loss: 0.3757 - val_accuracy: 0.8302\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), \n",
    "          callbacks=[tensorboard_cb, safety], batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 28)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3712      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,353\n",
      "Trainable params: 20,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37568727135658264, 0.8302467465400696]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorsboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 88, 'n_hidden': 2}\n",
      "-0.36373191078503925\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      hp.Choice('units', [8, 16, 32]),\n",
    "      activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(.2, input_shape=(2,)))  \n",
    "  model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy())\n",
    "  return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 15s]\n",
      "val_loss: 0.37438350915908813\n",
      "\n",
      "Best val_loss So Far: 0.36611732840538025\n",
      "Total elapsed time: 00h 00m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=1000)\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fd7de744430>\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/particle_random_cv/assets\n"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.save('models/particle_random_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
