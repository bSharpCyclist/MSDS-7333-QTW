{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# understand matrix structure of vectorizer\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "words = ['one two three','one four five','two three six']\r\n",
    "vectorizer = CountVectorizer()\r\n",
    "\r\n",
    "vectorizer.fit(words)\r\n",
    "\r\n",
    "print(vectorizer.vocabulary_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'one': 2, 'two': 5, 'three': 4, 'four': 1, 'five': 0, 'six': 3}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sample = vectorizer.transform([words[0]])\r\n",
    "\r\n",
    "print(sample.toarray())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 1 0 1 1]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from os import listdir, getcwd, chdir\r\n",
    "from os.path import isfile, join, dirname, realpath\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "def get_cwd():\r\n",
    "    try:\r\n",
    "        chdir(dirname(realpath(__file__)))\r\n",
    "    except:\r\n",
    "        chdir('D:\\Projects\\MSDS-7333-QTW')\r\n",
    "\r\n",
    "    active_dir = getcwd()\r\n",
    "       \r\n",
    "    return active_dir\r\n",
    "\r\n",
    "def main():\r\n",
    "    \r\n",
    "    get_cwd()\r\n",
    "    \r\n",
    "    directories = [\r\n",
    "            'easy_ham',\r\n",
    "            'easy_ham_2',\r\n",
    "            'hard_ham',\r\n",
    "            'spam',\r\n",
    "            'spam_2'\r\n",
    "        ]\r\n",
    "    \r\n",
    "    res_frame = pd.DataFrame()\r\n",
    "\r\n",
    "    # *dc - Added to keep a collection of email text\r\n",
    "    emails = []\r\n",
    "        \r\n",
    "    for d in directories:\r\n",
    "        mypath = getcwd() + '/SpamAssassinMessages/' + d + '/'\r\n",
    "        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\r\n",
    "    \r\n",
    "        try:\r\n",
    "            onlyfiles.remove('.DS_Store')\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        \r\n",
    "        for file in onlyfiles:\r\n",
    "            with open(mypath + file, encoding='latin1') as f:\r\n",
    "                lines = f.readlines()\r\n",
    "                f.close()\r\n",
    "                \r\n",
    "            in_reply_count = 0\r\n",
    "            sub_line_all_caps = 0\r\n",
    "            attachments = 0\r\n",
    "            subject_line = []\r\n",
    "            n_lines = 0\r\n",
    "            blank_lines = []\r\n",
    "            \r\n",
    "            for line in lines:\r\n",
    "\r\n",
    "                n_lines += 1\r\n",
    "                if \"Subject: Re: \" in line:\r\n",
    "                   in_reply_count += 1\r\n",
    "                if \"Subject: \" in line:\r\n",
    "                   s_line = line.strip().replace('Subject: ','')\r\n",
    "                   s_line = ''.join(e for e in s_line if e.isalnum())\r\n",
    "                   num_upper = sum(1 for c in s_line if c.isupper())\r\n",
    "                   ttl_chars = len(s_line)\r\n",
    "                   if num_upper == ttl_chars:\r\n",
    "                       sub_line_all_caps += 1\r\n",
    "                   subject_line.append(s_line)\r\n",
    "                if \"content-type: multipart\" in line.lower():\r\n",
    "                   attachments += 1\r\n",
    "                if line == \"\\n\":\r\n",
    "                   blank_lines.append(n_lines)\r\n",
    "        \r\n",
    "            temp_frame = pd.DataFrame({\r\n",
    "                        'directory':d,    \r\n",
    "                        'filename':file,\r\n",
    "                        'is_spam':['Y' if 'spam' in d else 'N'],\r\n",
    "                        'in_reply': ['Y' if in_reply_count > 0 else 'N'], \r\n",
    "                        'subj_caps': ['Y' if sub_line_all_caps > 0 else 'N'], \r\n",
    "                        'attachments': ['Y' if attachments > 0 else 'N'],\r\n",
    "                        ## *dc+3 \r\n",
    "                        #'body_lines': n_lines - min(blank_lines)\r\n",
    "                        'body_lines': [0 if len(blank_lines) == 0 else min(blank_lines)]\r\n",
    "                        }, index=[0])\r\n",
    "           \r\n",
    "            res_frame = res_frame.append(temp_frame, ignore_index=True)\r\n",
    "\r\n",
    "            ## *dc+2\r\n",
    "            # append body of email to collection\r\n",
    "            text = ' '.join(lines)\r\n",
    "            emails.append(text)\r\n",
    "            \r\n",
    "    #res_frame.to_csv('output_file.csv', index=False)\r\n",
    "    \r\n",
    "    ## *dc - add emails\r\n",
    "    return res_frame, emails\r\n",
    "\r\n",
    "## *dc - Working from a notebook instead of py file.\r\n",
    "df, emails = main()\r\n",
    "# ########################################\r\n",
    "# ##### Main Function\r\n",
    "# ########################################    \r\n",
    "# if __name__ == \"__main__\":\r\n",
    "#     res_frame, emails = main()\r\n",
    "#     pass   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(len(df),len(emails))\r\n",
    "\r\n",
    "print(emails[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9353 9353\n",
      "From exmh-workers-admin@redhat.com  Thu Aug 22 12:36:23 2002\n",
      " Return-Path: <exmh-workers-admin@spamassassin.taint.org>\n",
      " Delivered-To: zzzz@localhost.netnoteinc.com\n",
      " Received: from localhost (localhost [127.0.0.1])\n",
      " \tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id D03E543C36\n",
      " \tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:36:16 -0400 (EDT)\n",
      " Received: from phobos [127.0.0.1]\n",
      " \tby localhost with IMAP (fetchmail-5.9.0)\n",
      " \tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:36:16 +0100 (IST)\n",
      " Received: from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by\n",
      "     dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MBYrZ04811 for\n",
      "     <zzzz-exmh@spamassassin.taint.org>; Thu, 22 Aug 2002 12:34:53 +0100\n",
      " Received: from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by\n",
      "     listman.redhat.com (Postfix) with ESMTP id 8386540858; Thu, 22 Aug 2002\n",
      "     07:35:02 -0400 (EDT)\n",
      " Delivered-To: exmh-workers@listman.spamassassin.taint.org\n",
      " Received: from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org\n",
      "     [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 10CF8406D7\n",
      "     for <exmh-workers@listman.redhat.com>; Thu, 22 Aug 2002 07:34:10 -0400\n",
      "     (EDT)\n",
      " Received: (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)\n",
      "     id g7MBY7g11259 for exmh-workers@listman.redhat.com; Thu, 22 Aug 2002\n",
      "     07:34:07 -0400\n",
      " Received: from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by\n",
      "     int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7MBY7Y11255 for\n",
      "     <exmh-workers@redhat.com>; Thu, 22 Aug 2002 07:34:07 -0400\n",
      " Received: from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org\n",
      "     (8.11.6/8.11.6) with SMTP id g7MBIhl25223 for <exmh-workers@redhat.com>;\n",
      "     Thu, 22 Aug 2002 07:18:55 -0400\n",
      " Received: from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by\n",
      "     ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7MBWel29762;\n",
      "     Thu, 22 Aug 2002 18:32:40 +0700 (ICT)\n",
      " Received: from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU\n",
      "     (8.11.6/8.11.6) with ESMTP id g7MBQPW13260; Thu, 22 Aug 2002 18:26:25\n",
      "     +0700 (ICT)\n",
      " From: Robert Elz <kre@munnari.OZ.AU>\n",
      " To: Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      " Cc: exmh-workers@spamassassin.taint.org\n",
      " Subject: Re: New Sequences Window\n",
      " In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      " References: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "     <1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\n",
      "     <1029943066.26919.TMDA@deepeddy.vircio.com>\n",
      "     <1029944441.398.TMDA@deepeddy.vircio.com>\n",
      " MIME-Version: 1.0\n",
      " Content-Type: text/plain; charset=us-ascii\n",
      " Message-Id: <13258.1030015585@munnari.OZ.AU>\n",
      " X-Loop: exmh-workers@spamassassin.taint.org\n",
      " Sender: exmh-workers-admin@spamassassin.taint.org\n",
      " Errors-To: exmh-workers-admin@spamassassin.taint.org\n",
      " X-Beenthere: exmh-workers@spamassassin.taint.org\n",
      " X-Mailman-Version: 2.0.1\n",
      " Precedence: bulk\n",
      " List-Help: <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
      " List-Post: <mailto:exmh-workers@spamassassin.taint.org>\n",
      " List-Subscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "     <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
      " List-Id: Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
      " List-Unsubscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "     <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
      " List-Archive: <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
      " Date: Thu, 22 Aug 2002 18:26:25 +0700\n",
      " \n",
      "     Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "     From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "     Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      " \n",
      " \n",
      "   | I can't reproduce this error.\n",
      " \n",
      " For me it is very repeatable... (like every time, without fail).\n",
      " \n",
      " This is the debug log of the pick happening ...\n",
      " \n",
      " 18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      " 18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      " 18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      " 18:19:04 Marking 1 hits\n",
      " 18:19:04 tkerror: syntax error in expression \"int ...\n",
      " \n",
      " Note, if I run the pick command by hand ...\n",
      " \n",
      " delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
      " 1 hit\n",
      " \n",
      " That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
      " using is ...\n",
      " \n",
      " delta$ pick -version\n",
      " pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
      " \n",
      " And the relevant part of my .mh_profile ...\n",
      " \n",
      " delta$ mhparam pick\n",
      " -seq sel -list\n",
      " \n",
      " \n",
      " Since the pick command works, the sequence (actually, both of them, the\n",
      " one that's explicit on the command line, from the search popup, and the\n",
      " one that comes from .mh_profile) do get created.\n",
      " \n",
      " kre\n",
      " \n",
      " ps: this is still using the version of the code form a day ago, I haven't\n",
      " been able to reach the cvs repository today (local routing issue I think).\n",
      " \n",
      " \n",
      " \n",
      " _______________________________________________\n",
      " Exmh-workers mailing list\n",
      " Exmh-workers@redhat.com\n",
      " https://listman.redhat.com/mailman/listinfo/exmh-workers\n",
      " \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import nltk\r\n",
    "import re \r\n",
    "import numpy as np\r\n",
    "\r\n",
    "stop_words = nltk.corpus.stopwords.words('english')\r\n",
    "\r\n",
    "def normalize_document(doc):\r\n",
    "    # lowercase and remove special characters to form a normalized document\r\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\r\n",
    "    doc = doc.lower()\r\n",
    "    doc = doc.strip()\r\n",
    "\r\n",
    "    # tokenize document\r\n",
    "    tokens = nltk.word_tokenize(doc)\r\n",
    "    \r\n",
    "    # filter out stop words\r\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\r\n",
    "\r\n",
    "    # Remove numbers\r\n",
    "    filtered_tokens = [token for token in filtered_tokens if not token.isdigit()]\r\n",
    "\r\n",
    "    # Remove short tokens\r\n",
    "    filtered_tokens = [token for token in filtered_tokens if len(token) > 2]\r\n",
    "\r\n",
    "    # stem tokens - Skipping for now\r\n",
    "    #filtered_tokens = [stemming.stem(token) for token in filtered_tokens]\r\n",
    "\r\n",
    "    # re-create a normalized document\r\n",
    "    doc = ' '.join(filtered_tokens)\r\n",
    "    return doc\r\n",
    "\r\n",
    "normalize_text = np.vectorize(normalize_document)\r\n",
    "norm_text = normalize_text(emails)\r\n",
    "\r\n",
    "print(type(norm_text),len(norm_text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'> 9353\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "tf = TfidfVectorizer(ngram_range=(1,3), min_df=5, max_df=.8, stop_words=stop_words, norm='l2')\r\n",
    "tf_matrix = tf.fit_transform(norm_text)\r\n",
    "\r\n",
    "print(tf_matrix.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9353, 166742)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "cv = CountVectorizer(min_df=0, max_df=1., stop_words=stop_words)\r\n",
    "cv_matrix = cv.fit_transform(norm_text)\r\n",
    "\r\n",
    "print(cv_matrix.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(df.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['directory', 'filename', 'is_spam', 'in_reply', 'subj_caps',\n",
      "       'attachments', 'body_lines'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\r\n",
    "\r\n",
    "NUM_CLUSTERS = 5\r\n",
    "km = KMeans(n_clusters=NUM_CLUSTERS, max_iter=10000, n_init=50, random_state=42).fit(tf_matrix)\r\n",
    "km\r\n",
    "\r\n",
    "df['kmeans_cluster'] = km.labels_\r\n",
    "\r\n",
    "email_clusters = (df[['directory', 'kmeans_cluster']]\r\n",
    "                  .sort_values(by=['kmeans_cluster'], \r\n",
    "                               ascending=False)\r\n",
    "                  .groupby('kmeans_cluster').head(20))  # top 20 movies for each cluster\r\n",
    "email_clusters = email_clusters.copy(deep=True)\r\n",
    "\r\n",
    "feature_names = tf.get_feature_names()\r\n",
    "topn_features = 50\r\n",
    "ordered_centroids = km.cluster_centers_.argsort()[:, ::-1]\r\n",
    "\r\n",
    "sample_silhouette_values = silhouette_samples(tf_matrix, km.labels_)\r\n",
    "\r\n",
    "# get key features for each cluster\r\n",
    "for cluster_num in range(NUM_CLUSTERS):\r\n",
    "\r\n",
    "    cluster_silhouette_values = sample_silhouette_values[km.labels_ == cluster_num]\r\n",
    "\r\n",
    "    key_features = [feature_names[index] \r\n",
    "                        for index in ordered_centroids[cluster_num, :topn_features]]\r\n",
    "    print('CLUSTER #'+str(cluster_num+1), \":\", cluster_silhouette_values.mean())\r\n",
    "    print('Cluster Size', cluster_silhouette_values.shape[0])\r\n",
    "    print('Key Features:', key_features)\r\n",
    "    print('-'*80)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CLUSTER #1 : 0.2410520400548465\n",
      "Cluster Size 771\n",
      "Key Features: ['sourceforge net', 'sourceforge', 'net', 'razor', 'razor users', 'example sourceforge net', 'example sourceforge', 'spamassassin talk', 'talk', 'lists', 'spamassassin', 'lists sourceforge net', 'lists sourceforge', 'usw', 'users', 'example', 'spamassassin devel', 'devel', 'sourceforge net subject', 'aug', 'list', 'sf', 'list1 sourceforge', 'list1 sourceforge net', 'list1', 'admin example sourceforge', 'usw list1 sourceforge', 'usw list1', 'sourceforge net lists', 'net lists', 'lists listinfo', 'net lists listinfo', 'https', 'admin example', 'mailto spamassassin', 'net subject', 'net usw', 'talk admin', 'mailto spamassassin talk', 'talk example', 'talk example sourceforge', 'spamassassin talk admin', 'received usw', 'sourceforge net usw', 'thu', 'spamassassin talk example', 'list2 sourceforge', 'list2', 'list2 sourceforge net', 'usw list2 sourceforge']\n",
      "--------------------------------------------------------------------------------\n",
      "CLUSTER #2 : 0.008204633306760849\n",
      "Cluster Size 5372\n",
      "Key Features: ['3d', 'font', 'oct', 'rssfeeds', 'sep', 'exmh', 'taint org', 'taint', 'example com', 'spamassassin taint', 'spamassassin taint org', 'spamassassin', 'width', 'example', 'tue', 'size', 'net', 'thu', 'td', 'www', 'jmason', 'jmason org', 'http www', 'tue oct', 'aug', 'jalapeno', 'wed', 'zzzz', 'exmh users', 'nbsp', 'color', 'mon', 'face', 'thu sep', 'yahoo', 'html', 'rssfeeds spamassassin taint', 'rssfeeds spamassassin', 'redhat com', 'yyyy', 'rssfeeds example', 'rssfeeds example com', 'exmh workers', 'height', 'oct ist', 'oct ist received', 'href', 'workers', 'perl', 'yahoo com']\n",
      "--------------------------------------------------------------------------------\n",
      "CLUSTER #3 : 0.1803789278946065\n",
      "Cluster Size 802\n",
      "Key Features: ['ilug', 'linux', 'ie', 'linux ie', 'lugh', 'ilug linux', 'tuatha org', 'tuatha', 'lugh tuatha org', 'lugh tuatha', 'admin linux', 'ilug admin', 'ilug admin linux', 'aug', 'ilug linux ie', 'irish', 'irish linux', 'irish linux users', 'linux users group', 'users group', 'linux users', 'users group ilug', 'group ilug', 'group ilug linux', 'received lugh', 'root', 'admin', 'ie mailman', 'linux ie mailman', 'social', 'group', 'tuatha org esmtp', 'users', 'jul', 'admin linux ie', 'www linux', 'http www linux', 'tue aug', 'www linux ie', 'root localhost', 'fri', 'ie mailman listinfo', 'tue', 'fri aug', 'listinfo ilug', 'mailman listinfo ilug', 'list', 'mailman', 'received lugh tuatha', 'zzzz']\n",
      "--------------------------------------------------------------------------------\n",
      "CLUSTER #4 : 0.18631600295736175\n",
      "Cluster Size 1750\n",
      "Key Features: ['fork', 'xent com', 'xent', 'fork admin', 'fork admin xent', 'admin xent', 'admin xent com', 'mailto fork', 'sep', 'http xent com', 'http xent', 'list', 'xent com subject', 'fork request xent', 'request xent com', 'fork request', 'request xent', 'mailto fork request', 'fork spamassassin', 'fork spamassassin taint', 'admin', 'mailto', 'com mailman', 'fork xent', 'fork xent com', 'xent com mailman', 'listinfo fork', 'mailman listinfo fork', 'com subject', 'mailman', 'com mailman listinfo', 'spamassassin taint', 'spamassassin taint org', 'request', 'taint org', 'fork example', 'fork example com', 'taint', 'aug', 'xent com postfix', 'fork mailto fork', 'fork mailto', 'listinfo fork mailto', 'pdt', 'spamassassin', 'mailman listinfo', 'example com', 'mon', 'com postfix', 'listinfo']\n",
      "--------------------------------------------------------------------------------\n",
      "CLUSTER #5 : 0.3525919250064833\n",
      "Cluster Size 658\n",
      "Key Features: ['rpm', 'freshrpms', 'freshrpms net', 'zzzlist', 'rpm zzzlist', 'net', 'rpm list', 'egwn', 'list', 'egwn net', 'zzzlist freshrpms', 'zzzlist freshrpms net', 'rpm zzzlist freshrpms', 'http lists freshrpms', 'lists freshrpms', 'lists freshrpms net', 'freshrpms net mailman', 'http lists', 'admin freshrpms', 'admin freshrpms net', 'mailto rpm', 'freshrpms net subject', 'net mailman', 'mailman listinfo rpm', 'listinfo rpm', 'net mailman listinfo', 'request freshrpms', 'request freshrpms net', 'zzzlist admin freshrpms', 'zzzlist admin', 'rpm zzzlist admin', 'freshrpms net list', 'matthias', 'list freshrpms', 'rpm list freshrpms', 'list freshrpms net', 'lists', 'net subject', 'oct', 'net list', 'net egwn', 'list rpm', 'mailto rpm list', 'rpm list request', 'list request freshrpms', 'list request', 'egwn net egwn', 'mailto rpm zzzlist', 'listinfo rpm zzzlist', 'rpm zzzlist mailto']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "## Output a quick pivot table to see distribution of clusters vs spam/ham\r\n",
    "\r\n",
    "df.pivot_table(index='kmeans_cluster', columns='is_spam', values='directory', aggfunc='count')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_spam</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>748.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3158.0</td>\n",
       "      <td>2214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>692.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1698.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_spam              N       Y\n",
       "kmeans_cluster                \n",
       "0                748.0    23.0\n",
       "1               3158.0  2214.0\n",
       "2                692.0   110.0\n",
       "3               1698.0    52.0\n",
       "4                658.0     NaN"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('NLP': conda)"
  },
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}