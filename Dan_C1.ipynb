{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1\r\n",
    "\r\n",
    "## Business Understanding\r\n",
    "You should always state the objective at the beginning of every case (a guideline you should follow in real life as well) and provide some initial \"Business Understanding\" statements (i.e., what is trying to be solved for and why might it be important)\r\n",
    "\r\n",
    "build a linear regression model using L1 or L2 regularization (or both) to predict the critical temperature. In addition, include in your write-up which variable carries the most importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluation and Engineering\r\n",
    "Summarize the data being used in the case using appropriate mediums (charts, graphs, tables); address questions such as: Are there missing values? Which variables are needed (which ones are not)? What assumptions or conclusions are you drawing that need to be relayed to your audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21263 entries, 0 to 21262\n",
      "Columns: 169 entries, number_of_elements to material\n",
      "dtypes: float64(156), int64(12), object(1)\n",
      "memory usage: 27.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Load Data\r\n",
    "data_train = pd.read_csv('./data/train.csv')\r\n",
    "data_materials = pd.read_csv('./data/unique_m.csv')\r\n",
    "\r\n",
    "# Drop the duplicate column 'critical_temp' in the\r\n",
    "\r\n",
    "data_train = data_train.drop(['critical_temp'], axis=1)\r\n",
    "\r\n",
    "# Merge the two frames\r\n",
    "data = pd.merge(data_train, data_materials, left_index=True, right_index=True)\r\n",
    "\r\n",
    "data.info()\r\n",
    "data.describe()\r\n",
    "\r\n",
    "# Data frame to csv drop index\r\n",
    "data.to_csv('./data/super_conducter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Columns with missing data?\r\n",
    "print(data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['He', 'Ne', 'Ar', 'Kr', 'Xe', 'Pm', 'Po', 'At', 'Rn'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with a Constant value\r\n",
    "data.columns[data.nunique() <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21263, 159)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with constant values\r\n",
    "data.drop(columns=['material', 'He', 'Ne', 'Ar', 'Kr', 'Xe', 'Pm', 'Po', 'At', 'Rn'], inplace=True)\r\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our standard numpy stuff\r\n",
    "df_X = data.drop(columns=['critical_temp']).copy(deep=True)\r\n",
    "df_y = data.loc[:,'critical_temp'].copy(deep=True)\r\n",
    "\r\n",
    "X = df_X.values\r\n",
    "y = df_y.values\r\n",
    "\r\n",
    "# X_df = data.drop(columns=['critical_temp']).copy(deep=True)\r\n",
    "\r\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\r\n",
    "\r\n",
    "# vif_data = pd.DataFrame()\r\n",
    "# vif_data[\"feature\"] = X_df.columns\r\n",
    "\r\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(len(X_df.columns))]\r\n",
    "\r\n",
    "# vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "0.6708240841303161\n",
      "{'lasso__alpha': 0.1}\n",
      "\n",
      "Ridge\n",
      "0.6654620463589576\n",
      "{'ridge__alpha': 100}\n",
      "\n",
      "Elastic\n",
      "0.6672340883732841\n",
      "{'elasticnet__alpha': 0.01, 'elasticnet__l1_ratio': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stats.stackexchange.com/questions/445259/combining-pca-feature-scaling-and-cross-validation-without-training-test-data\r\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import RobustScaler\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.linear_model import Lasso\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import ElasticNet\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test =\\\r\n",
    "    train_test_split(df_X, df_y,\r\n",
    "    test_size=0.2,\r\n",
    "    random_state=1)\r\n",
    "\r\n",
    "lasso_pipe_svc = make_pipeline(MinMaxScaler(), Lasso(random_state=1))\r\n",
    "ridge_pipe_svc = make_pipeline(MinMaxScaler(), Ridge(random_state=1))\r\n",
    "elastic_pipe_svc = make_pipeline(MinMaxScaler(), ElasticNet(random_state=1))\r\n",
    "\r\n",
    "#pipe_svc = make_pipeline(RobustScaler(), Ridge(random_state=1))\r\n",
    "#pipe_svc = make_pipeline(StandardScaler(), Lasso(random_state=1))\r\n",
    "\r\n",
    "#param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\r\n",
    "param_range = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 10, 100, 1000, 10000]\r\n",
    "param_l1_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\r\n",
    "\r\n",
    "param_grid_lasso = [{'lasso__alpha': param_range}]\r\n",
    "param_grid_ridge = [{'ridge__alpha': param_range}]\r\n",
    "param_grid_elastic = [{'elasticnet__alpha': param_range, 'elasticnet__l1_ratio': param_l1_ratio}]\r\n",
    "\r\n",
    "gs_lasso = GridSearchCV(estimator=lasso_pipe_svc, param_grid=param_grid_lasso, scoring='r2', cv=5, n_jobs=-1)\r\n",
    "gs_lasso.fit(X_train, y_train)\r\n",
    "\r\n",
    "gs_ridge = GridSearchCV(estimator=ridge_pipe_svc, param_grid=param_grid_ridge, scoring='r2', cv=5, n_jobs=-1)\r\n",
    "gs_ridge.fit(X_train, y_train)\r\n",
    "\r\n",
    "gs_elastic = GridSearchCV(estimator=elastic_pipe_svc, param_grid=param_grid_elastic, scoring='r2', cv=5, n_jobs=-1)\r\n",
    "gs_elastic.fit(X_train, y_train)\r\n",
    "\r\n",
    "print(\"Lasso\")\r\n",
    "print(gs_lasso.best_score_)\r\n",
    "print(gs_lasso.best_params_)\r\n",
    "print(\"\")\r\n",
    "\r\n",
    "print(\"Ridge\")\r\n",
    "print(gs_ridge.best_score_)\r\n",
    "print(gs_ridge.best_params_)\r\n",
    "print(\"\")\r\n",
    "\r\n",
    "print(\"Elastic\")\r\n",
    "print(gs_elastic.best_score_)\r\n",
    "print(gs_elastic.best_params_)\r\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R2 -> 0.7197254814065868\n",
      "MAE -> 13.660714491348584\n",
      "\n",
      "Ridge\n",
      "R2 -> 0.7264906957630273\n",
      "MAE -> 13.359929361601825\n",
      "\n",
      "Elastic\n",
      "R2 -> 0.7146988481193569\n",
      "MAE -> 13.811785860925973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\r\n",
    "\r\n",
    "# Note the X_test gets run through the pipeline above! Very important, it means that the scaler is also run on the test data\r\n",
    "y_lasso_pred = gs_lasso.predict(X_test)\r\n",
    "y_ridge_pred = gs_ridge.predict(X_test)\r\n",
    "y_elastic_pred = gs_elastic.predict(X_test)\r\n",
    "\r\n",
    "print(\"Lasso\")\r\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_lasso_pred))\r\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_lasso_pred))\r\n",
    "print(\"\")\r\n",
    "\r\n",
    "print(\"Ridge\")\r\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_ridge_pred))\r\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_ridge_pred))\r\n",
    "print(\"\")\r\n",
    "\r\n",
    "print(\"Elastic\")\r\n",
    "print(\"R2 ->\", metrics.r2_score(y_test, y_elastic_pred))\r\n",
    "print(\"MAE ->\", metrics.mean_absolute_error(y_test, y_elastic_pred))\r\n",
    "print(\"\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_elements 0.0\n",
      "mean_atomic_mass -0.0\n",
      "wtd_mean_atomic_mass -0.0\n",
      "gmean_atomic_mass -0.0\n",
      "wtd_gmean_atomic_mass -0.0\n",
      "entropy_atomic_mass 0.0\n",
      "wtd_entropy_atomic_mass 3.9508095199980304\n",
      "range_atomic_mass 6.955103730407498\n",
      "wtd_range_atomic_mass -1.2028148462719683\n",
      "std_atomic_mass 0.0\n",
      "wtd_std_atomic_mass -0.7363630703449164\n",
      "mean_fie 1.5836528543493764\n",
      "wtd_mean_fie 0.0\n",
      "gmean_fie 0.0\n",
      "wtd_gmean_fie 0.0\n",
      "entropy_fie 0.0\n",
      "wtd_entropy_fie 0.0\n",
      "range_fie 0.0\n",
      "wtd_range_fie 0.0\n",
      "std_fie 0.0\n",
      "wtd_std_fie 0.0\n",
      "mean_atomic_radius -0.0\n",
      "wtd_mean_atomic_radius 0.0\n",
      "gmean_atomic_radius -0.0\n",
      "wtd_gmean_atomic_radius -0.0\n",
      "entropy_atomic_radius 0.0\n",
      "wtd_entropy_atomic_radius 0.0\n",
      "range_atomic_radius 1.1880683928528302\n",
      "wtd_range_atomic_radius -0.0\n",
      "std_atomic_radius 0.0\n",
      "wtd_std_atomic_radius 0.0\n",
      "mean_Density -1.7386569847400537\n",
      "wtd_mean_Density -0.0\n",
      "gmean_Density -0.0\n",
      "wtd_gmean_Density -0.0\n",
      "entropy_Density -0.0\n",
      "wtd_entropy_Density 0.0\n",
      "range_Density 0.0\n",
      "wtd_range_Density 0.5578557645139761\n",
      "std_Density 0.0\n",
      "wtd_std_Density -0.2711147428607582\n",
      "mean_ElectronAffinity -0.0\n",
      "wtd_mean_ElectronAffinity -0.0\n",
      "gmean_ElectronAffinity -0.0\n",
      "wtd_gmean_ElectronAffinity -4.328328539587897\n",
      "entropy_ElectronAffinity -0.0\n",
      "wtd_entropy_ElectronAffinity -2.5435733987843343\n",
      "range_ElectronAffinity 0.0\n",
      "wtd_range_ElectronAffinity -0.0\n",
      "std_ElectronAffinity 0.419474827926435\n",
      "wtd_std_ElectronAffinity -0.0\n",
      "mean_FusionHeat 0.0\n",
      "wtd_mean_FusionHeat 0.0\n",
      "gmean_FusionHeat 0.0\n",
      "wtd_gmean_FusionHeat 0.0\n",
      "entropy_FusionHeat 0.0\n",
      "wtd_entropy_FusionHeat 2.8062532004771885\n",
      "range_FusionHeat -0.0\n",
      "wtd_range_FusionHeat 0.5820119169251454\n",
      "std_FusionHeat 0.0\n",
      "wtd_std_FusionHeat -1.046997414247526\n",
      "mean_ThermalConductivity 0.9839999275894176\n",
      "wtd_mean_ThermalConductivity 11.947603500510482\n",
      "gmean_ThermalConductivity -0.0\n",
      "wtd_gmean_ThermalConductivity -12.364521222651708\n",
      "entropy_ThermalConductivity 0.0\n",
      "wtd_entropy_ThermalConductivity 3.924730652055882\n",
      "range_ThermalConductivity 0.0\n",
      "wtd_range_ThermalConductivity -0.0\n",
      "std_ThermalConductivity 0.0\n",
      "wtd_std_ThermalConductivity 0.0\n",
      "mean_Valence -0.0\n",
      "wtd_mean_Valence -0.0\n",
      "gmean_Valence -0.0\n",
      "wtd_gmean_Valence -0.0\n",
      "entropy_Valence 0.0\n",
      "wtd_entropy_Valence 0.0\n",
      "range_Valence 0.0\n",
      "wtd_range_Valence 0.0\n",
      "std_Valence -0.0\n",
      "wtd_std_Valence -6.5603440594602995\n",
      "H -0.0\n",
      "Li 0.0\n",
      "Be -0.0\n",
      "B -0.3381522940299983\n",
      "C 0.12906196232215852\n",
      "N -0.0\n",
      "O 0.0\n",
      "F 0.0\n",
      "Na -0.0\n",
      "Mg 0.0\n",
      "Al -0.32446796220072877\n",
      "Si -1.6972961033719114\n",
      "P -0.0\n",
      "S -1.0526391079045863\n",
      "Cl -0.0\n",
      "K 0.0\n",
      "Ca 3.3178161344471087\n",
      "Sc 0.0\n",
      "Ti -0.16585668759745884\n",
      "V 0.12640116643325944\n",
      "Cr 0.0\n",
      "Mn -0.0\n",
      "Fe -0.0\n",
      "Co -0.0\n",
      "Ni -0.0\n",
      "Cu -0.0\n",
      "Zn -0.0\n",
      "Ga -0.0\n",
      "Ge -0.5532431718577415\n",
      "As -1.1522532857677543\n",
      "Se -0.0\n",
      "Br -0.0\n",
      "Rb 0.0\n",
      "Sr 1.3418330269172292\n",
      "Y 0.0\n",
      "Zr -0.05164513864755047\n",
      "Nb 0.1480172271062835\n",
      "Mo -0.021814294515427206\n",
      "Tc 0.0\n",
      "Ru -0.0\n",
      "Rh -0.0\n",
      "Pd -0.03141891595180431\n",
      "Ag -0.0\n",
      "Cd -0.0\n",
      "In -0.0\n",
      "Sn 0.0\n",
      "Sb -0.0\n",
      "Te -0.0\n",
      "I 0.0\n",
      "Cs 0.0\n",
      "Ba 12.747910288530562\n",
      "La -0.12478981428672298\n",
      "Ce -0.0\n",
      "Pr -0.0\n",
      "Nd -0.0\n",
      "Sm 0.0\n",
      "Eu -0.0\n",
      "Gd -0.0\n",
      "Tb 0.0\n",
      "Dy 0.0\n",
      "Ho 0.0\n",
      "Er 0.0\n",
      "Tm -0.0\n",
      "Yb 0.0\n",
      "Lu 0.0\n",
      "Hf -0.0\n",
      "Ta -0.0\n",
      "W -0.0\n",
      "Re 0.0\n",
      "Os 0.0\n",
      "Ir -0.0\n",
      "Pt -0.0\n",
      "Au -0.0\n",
      "Hg 0.0\n",
      "Tl 0.16003493811249433\n",
      "Pb 0.0\n",
      "Bi 3.97490881456744\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "#print()\r\n",
    "#print(gs.best_estimator_['lasso'].coef_)\r\n",
    "idx = 0\r\n",
    "cnt = 0\r\n",
    "\r\n",
    "cols_to_drop = []\r\n",
    "\r\n",
    "for x in gs.best_estimator_['lasso'].coef_:\r\n",
    "    print(data.columns[idx], x)\r\n",
    "    idx += 1\r\n",
    "    if x == 0:\r\n",
    "        cnt += 1\r\n",
    "        cols_to_drop.append(data.columns[idx])\r\n",
    "\r\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data.drop(columns=cols_to_drop).copy(deep=True)\r\n",
    "\r\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\r\n",
    "\r\n",
    "# vif_data = pd.DataFrame()\r\n",
    "# vif_data[\"feature\"] = X_df.columns\r\n",
    "\r\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(len(X_df.columns))]\r\n",
    "\r\n",
    "# vif_data\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6238304226639614\n",
      "{'ridge__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "X = X_df.drop(columns=['critical_temp']).values\r\n",
    "y = data.loc[:,'critical_temp'].values\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test =\\\r\n",
    "    train_test_split(X, y,\r\n",
    "    test_size=0.2,\r\n",
    "    random_state=1)\r\n",
    "\r\n",
    "pipe_svc = make_pipeline(RobustScaler(), Ridge(random_state=1))\r\n",
    "#pipe_svc = make_pipeline(StandardScaler(), LogisticRegression(random_state=1))\r\n",
    "\r\n",
    "\r\n",
    "#param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\r\n",
    "param_range = [0.001, 0.01, 0.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\r\n",
    "\r\n",
    "param_grid = [{'ridge__alpha': param_range}]\r\n",
    "\r\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='r2', cv=5, n_jobs=-1)\r\n",
    "\r\n",
    "gs = gs.fit(X_train, y_train)\r\n",
    "\r\n",
    "print(gs.best_score_)\r\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6145652115524546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.predict(X_test)\r\n",
    "\r\n",
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_elements 13.487984851692977\n",
      "mean_atomic_mass 2.1225100001983446\n",
      "wtd_mean_atomic_mass 10.782705622339384\n",
      "gmean_atomic_mass -1.6643535094439528\n",
      "wtd_gmean_atomic_mass -4.4237126509847595\n",
      "entropy_atomic_mass 6.813374319059292\n",
      "wtd_entropy_atomic_mass -3.2098067719137777\n",
      "range_atomic_mass -6.847940527216241\n",
      "wtd_range_atomic_mass -9.951626110077674\n",
      "std_atomic_mass -1.9779067752527328\n",
      "wtd_std_atomic_mass -0.9980228629792511\n",
      "mean_fie 9.16635842901707\n",
      "wtd_mean_fie 10.102564790255299\n",
      "gmean_fie -12.722713655854113\n",
      "wtd_gmean_fie 1.7175514479907312\n",
      "entropy_fie -1.7438329957558216\n",
      "wtd_entropy_fie -7.783179803536447\n",
      "range_fie -1.4902019294386373\n",
      "wtd_range_fie -2.67511739351774\n",
      "std_fie 0.12378026980299667\n",
      "wtd_std_fie 0.0\n",
      "mean_atomic_radius 0.010917606394030163\n",
      "wtd_mean_atomic_radius 6.913627781183965\n",
      "gmean_atomic_radius 0.19085865282896503\n",
      "wtd_gmean_atomic_radius -0.07433270804044217\n",
      "entropy_atomic_radius -0.3582102473971797\n",
      "wtd_entropy_atomic_radius -13.022188142309568\n"
     ]
    }
   ],
   "source": [
    "idx = 0\r\n",
    "\r\n",
    "for x in gs.best_estimator_['lasso'].coef_:\r\n",
    "    print(data.columns[idx], x)\r\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 168/168 [00:01<00:00, 120.42it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s]\n"
     ]
    }
   ],
   "source": [
    "## install pandas 1.2.4\r\n",
    "## pip install pandas-profiling==2.8.0\r\n",
    "\r\n",
    "from pandas_profiling import ProfileReport\r\n",
    "\r\n",
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\", minimal=True)\r\n",
    "\r\n",
    "profile.to_file(output_file=\"PandasProfile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparations\r\n",
    "Which methods are you proposing to utilize to solve the problem?  Why is this method appropriate given the business objective? How will you determine if your approach is useful (or how will you differentiate which approach is more useful than another)?  More specifically, what evaluation metrics are most useful given that the problem is a regression one (ex., RMSE, logloss, MAE, etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation\r\n",
    "In this case, your primary task is to build a linear regression model using L1 or L2 regularization (or both) to predict the critical temperature and will involve the following steps:\r\n",
    "\r\n",
    "- Specify your sampling methodology\r\n",
    "- Setup your model(s) - specifying the regularization type chosen and including the parameters utilized by the model\r\n",
    "- Analyze your model's performance - referencing your chosen evaluation metric (including supplemental visuals and analysis where appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability & Explainability\r\n",
    "Using at least one of your models above (if multiple were trained):\r\n",
    "\r\n",
    "- Which variable(s) was (were) \"\"most important\"\" and why?  How did you come to the conclusion and how should your audience interpret this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Conclusions\r\n",
    "After all of your technical analysis and modeling; what are you proposing to your audience and why?  How should they view your results and what should they consider when moving forward?  Are there other approaches you'd recommend exploring?  This is where you \"bring it all home\" in language they understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.00000000e+00 9.27292140e+01 5.85184161e+01 7.31327872e+01\n",
      " 3.63966020e+01 1.44930919e+00 1.05775512e+00 1.22906070e+02\n",
      " 3.61619390e+01 4.70946332e+01 5.39798697e+01 7.66440000e+02\n",
      " 1.01061286e+03 7.20605511e+02 9.38745413e+02 1.54414454e+00\n",
      " 8.07078215e-01 8.10600000e+02 7.43164286e+02 2.90183029e+02\n",
      " 3.54963511e+02 1.61200000e+02 1.04971429e+02 1.41465215e+02\n",
      " 8.43701670e+01 1.50832754e+00 1.20411480e+00 2.05000000e+02\n",
      " 5.05714286e+01 6.73213191e+01 6.80088170e+01 5.82148580e+03\n",
      " 3.02101657e+03 1.23709508e+03 5.40957183e+01 1.31444218e+00\n",
      " 9.14802177e-01 1.04885710e+04 1.66738343e+03 3.76740318e+03\n",
      " 3.63264918e+03 9.08900000e+01 1.12316429e+02 6.98333146e+01\n",
      " 1.01166398e+02 1.42799655e+00 8.38666466e-01 1.27050000e+02\n",
      " 8.12078571e+01 4.94381674e+01 4.16676208e+01 7.78440000e+00\n",
      " 3.79685714e+00 4.40379050e+00 1.03525112e+00 1.37497728e+00\n",
      " 1.07309385e+00 1.28780000e+01 1.59571429e+00 4.47336265e+00\n",
      " 4.60300006e+00 1.72205316e+02 6.13723314e+01 1.60642279e+01\n",
      " 6.19734632e-01 8.47404163e-01 5.67706108e-01 4.29973420e+02\n",
      " 5.14133829e+01 1.98554600e+02 1.39630922e+02 2.00000000e+00\n",
      " 2.25714286e+00 1.88817502e+00 2.21067941e+00 1.55711310e+00\n",
      " 1.04722137e+00 2.00000000e+00 1.12857143e+00 6.32455532e-01\n",
      " 4.68606270e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e-01\n",
      " 1.90000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
